{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"paper_implement.ipynb","provenance":[],"mount_file_id":"1GOaQ4TxCQK1T116Mge4zhTBUMJ5sEE77","authorship_tag":"ABX9TyMHQKSDGhvvKgqXA1SOPrtK"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SEqO37HgpV8F","executionInfo":{"status":"ok","timestamp":1616350716917,"user_tz":-360,"elapsed":916,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"6469a82d-b994-471c-9529-5f2cea72d15e"},"source":["!git clone https://github.com/Holliemin9090/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"roLCkgJM7DgH"},"source":["import numpy as np\n","import cv2\n","from skimage.measure import label, regionprops\n","\n","\n","class Preprocess:\n","    def __init__(self, rawim, im, breast_mask, lesion_mask):\n","        self.raw = rawim\n","        self.image = im\n","        self.mask = breast_mask\n","        self.lesion_mask = lesion_mask\n","   \n","    def extract_breast_profile(image,lesion_mask, if_crop):\n","        \n","        breast_mask = np.zeros(np.shape(image))\n","        breast_mask[image>0]=1\n","        \n","        labelim = label(breast_mask)\n","        props =  regionprops(labelim)\n","#        find the largest object as the breast\n","        area = 0\n","        ind = 1\n","        for i in range(0,len(props)):\n","            if area<props[i].filled_area:\n","                area = props[i].filled_area\n","                ind = i+1\n","        breast_mask = np.zeros(np.shape(image))\n","        breast_mask[labelim==ind]=1  \n","        labelim = label(breast_mask)       \n","        props =  regionprops(labelim)\n","        boundingbox = props[0].bbox\n","#        crop the breast mask and mammogram\n","        if if_crop == 1:\n","            breast_mask = breast_mask[boundingbox[0]:boundingbox[2],boundingbox[1]:boundingbox[3]]\n","            breast_raw_image = image[boundingbox[0]:boundingbox[2],boundingbox[1]:boundingbox[3]]\n","            lesion_mask = lesion_mask[boundingbox[0]:boundingbox[2],boundingbox[1]:boundingbox[3]]\n","        else:\n","            breast_raw_image = image\n","#        breast_image = rescale2uint8(breast_raw_image,breast_mask)\n","        breast_image = rescale2uint16(breast_raw_image,breast_mask)\n","        return Preprocess(breast_raw_image,breast_image,breast_mask,lesion_mask)\n","    \n","def rescale2uint8(image,breast_mask):\n","    intensity_in_mask = image[breast_mask>0]\n","#    use top 0.2 percentile to do the strech\n","    maxi = np.percentile(intensity_in_mask,99.8)#np.max(intensity_in_mask)\n","    mini = np.percentile(intensity_in_mask,0.2)#np.min(intensity_in_mask)\n","#        stretch the image into 0~255\n","    \n","    image = 255*(image-mini)/(maxi-mini)\n","    image[breast_mask==0] = 0\n","    image[image<0] = 0\n","    image[image>255] = 255\n","    image = np.uint8(image)\n","          \n","    return image\n","\n","def rescale2uint16(image,breast_mask):\n","    intensity_in_mask = image[breast_mask>0]\n","#    use top 0.2 percentile to do the strech\n","    maxi = np.percentile(intensity_in_mask,99.8)#np.max(intensity_in_mask)\n","    mini = np.percentile(intensity_in_mask,0.2)#np.min(intensity_in_mask)\n","#        stretch the image into 0~255\n","    \n","    image = 65535*(image-mini)/(maxi-mini)\n","    image[breast_mask==0] = 0\n","    image[image<0] = 0\n","    image[image>65535] = 65535\n","    image = np.uint16(image)\n","          \n","    return image\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QEB-i6W87vTV"},"source":["import numpy as np\n","# To pad image into a square shape\n","def padimages(image,file_name, ratio):\n","    [length, width] = np.shape(image)\n","    if length/width>ratio:#1024/800\n","        print('This image needs padding.')\n","        add_wid = round(length*(1/ratio)-width)\n","        pad = np.zeros((length,add_wid))\n","        pad = pad.astype(image.dtype)\n","        if '_R_' in file_name:\n","        #                pad on the left\n","            pad_image = np.concatenate((pad,image),axis=1)\n","        else:\n","            pad_image = np.concatenate((image,pad),axis=1)\n","            \n","    return pad_image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wg9CgE368Ed1"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from skimage import data, color, io, img_as_float\n","\n","def mask_overlay(img, mask):\n","    alpha = 0.5\n","\n","    img = img_as_float(img)\n","    rows, cols = img.shape\n","    # Construct RGB version of grey-level image\n","    img_color = np.dstack((img, img, img))\n","    img_hsv = color.rgb2hsv(img_color)\n","    color_mask = np.zeros((rows, cols, 3))\n","    color_mask1 = color_mask[:,:,1]\n","    color_mask1[np.where(mask>0)] = 1\n","    color_mask[:,:,1] = color_mask1\n","    color_mask_hsv = color.rgb2hsv(color_mask)\n","    \n","    # Replace the hue and saturation of the original image\n","    # with that of the color mask\n","    img_hsv[..., 0] = color_mask_hsv[..., 0]\n","    img_hsv[..., 1] = color_mask_hsv[..., 1] * alpha\n","    \n","    img_masked = color.hsv2rgb(img_hsv)\n","    \n","    return img_masked"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKw3uH1now1e","executionInfo":{"status":"ok","timestamp":1616417526917,"user_tz":-360,"elapsed":1075,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"a340c586-9d1b-46dd-f70d-0379c02c01a3"},"source":["%cd \"/content/drive/MyDrive/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlOxkThdow5D","executionInfo":{"status":"ok","timestamp":1616417537256,"user_tz":-360,"elapsed":9711,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"8c262dff-729a-40c6-9352-44a19f45fdc9"},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Mon Nov 26 15:46:32 2018\n","\n","@author: Hang Min\n","\n","Prepare the mammograms for pseudo-color transformation\n","\n","To normalize the INbreast mammogram to 16bit\n","\n","To pad the mammograms and masks to a square\n","\n","\n","\"\"\"\n","\n","\n","\n","import os\n","import numpy as np\n","from Preprocess_mammo import Preprocess \n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import figure\n","from utility import padimages\n","#from skimage.segmentation import mark_boundaries\n","from skimage import io\n","from skimage.measure import label\n","from overlay import mask_overlay\n","import timeit\n","\n","start = timeit.default_timer()\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","#from skimage import data, color, io, img_as_float\n","\n","image_path = \"scans/raw_mammogram/\"\n","annotation_path = 'scans/raw_annotation/'\n","\n","save_image_path = \"scans/preprocessed_image/\"   \n","if not os.path.exists(save_image_path):        \n","    os.mkdir(save_image_path)\n"," \n","    \n","save_mask_path = \"scans/preprocessed_mask/\"    \n","if not os.path.exists(save_mask_path):        \n","    os.mkdir(save_mask_path)\n","\n","\n","file_names = os.listdir(image_path)    \n","file_names = sorted(file_names)\n","\n","\n","for i in range(0,len(file_names)):\n","\n","    print(file_names[i])\n","    mammo = io.imread(image_path+file_names[i],0)\n","   \n","    lesion_mask = io.imread(annotation_path+file_names[i])\n","    \n","    if np.max(lesion_mask)>=0:\n","#    Extract the breast profile and crop the mammogram, breast mask and the lesion mask\n","#    Normalize the image into 16-bit\n","        breast_preprocess = Preprocess.extract_breast_profile(mammo,lesion_mask,1)\n","               \n","        mammo = breast_preprocess.image\n","        breast_mask = breast_preprocess.mask\n","        lesion_mask =breast_preprocess.lesion_mask    \n","        \n","        print ('Number of lesions: '+str(np.max(np.unique(label(lesion_mask)))))\n","        \n","#   pad the image, to ensure the aspect ratio is 1:1\n","        pad_mammo = padimages(mammo,file_names[i],1)\n","        \n","#    save the preprocessed image\n","\n","        io.imsave(save_image_path + file_names[i],pad_mammo)\n","        \n","        #if the image has more than 1 lesion, then seperate them into different masks and number them.\n","        \n","        labelim = label(lesion_mask)\n","        if np.max(labelim)>0:\n","#            if there is at least 1 lesion.\n","            for l in range(1,np.max(labelim+1)):\n","                l_mask = np.zeros(np.shape(labelim))\n","                l_mask = l_mask.astype(lesion_mask.dtype)\n","                l_mask [labelim==l] = 255\n","                num_nonzero = np.where(l_mask>0)\n","                num_nonzero = len(num_nonzero[0])\n","\n","                if num_nonzero>15:\n","                    print('A valid mask')\n","#                   Pad the mask in the same way as padding the image\n","                    pad_l_mask = padimages(l_mask,file_names[i],1)\n","                    io.imsave(save_mask_path+file_names[i][:-4]+str(l)+'.png',pad_l_mask)\n","                else:\n","                    print('Has a tiny piece of noise that is not valid for training!')\n","                    \n","        else:# if there is no lesion\n","            pad_lesion_mask = padimages(lesion_mask,file_names[i],1)\n","            io.imsave(save_mask_path+file_names[i][:-4]+str(0)+'.png',pad_lesion_mask)\n","       \n","stop = timeit.default_timer()\n","print('RunTime per image: ', (stop - start)/ len(file_names)) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["22580192_5530d5782fc89dd7_MG_R_CC_ANON.png\n","Number of lesions: 1\n","This image needs padding.\n","A valid mask\n","This image needs padding.\n","RunTime per image:  7.0066864209999835\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cnULB-bT-y56","executionInfo":{"status":"ok","timestamp":1616350736781,"user_tz":-360,"elapsed":880,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"748255cd-f8d5-499f-de79-d507d51327f1"},"source":["!git clone https://github.com/matterport/Mask_RCNN.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'Mask_RCNN' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cj-CJgFN-1YV","executionInfo":{"status":"ok","timestamp":1616350743060,"user_tz":-360,"elapsed":3889,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"5deeaee0-5b0a-4378-dea3-6d07757fe24a"},"source":["import cv2\n","os.chdir('/content/drive/MyDrive/MaskRCNN-main/mrcnn/')\n","from Mask_RCNN.mrcnn import visualize\n","import Mask_RCNN.mrcnn.model as modellib"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ddu-SNZ4SSAO","executionInfo":{"status":"ok","timestamp":1616356119864,"user_tz":-360,"elapsed":1011,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"04146dc9-33f7-4b55-b1e7-d6b383b20b30"},"source":["print(ROOT_DIR)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"roRdr_auS2Us","executionInfo":{"status":"ok","timestamp":1616418437271,"user_tz":-360,"elapsed":2351,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"78c1373e-edcb-4d46-d30a-1004918c710e"},"source":["%cd \"//content//drive//MyDrive//Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kcdhkiB5VPbM"},"source":["ROOT_DIR = os.getcwd()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JzdRhnNXF0Lc"},"source":["!pip install keras==2.1.5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VFb8mhdBF0O-"},"source":["!pip install tensorflow==1.14.0\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XKzTzR5X_vPL","colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"status":"error","timestamp":1616418647449,"user_tz":-360,"elapsed":1230,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"ca8e43ec-e0d9-45d2-cb06-f6f8dfa9bcbc"},"source":["\n","import os\n","import sys\n","import json\n","import datetime\n","import numpy as np\n","import skimage.draw\n","import matplotlib.image\n","import glob\n","import scipy.misc\n","from PIL import Image\n","#import imgaug \n","from imgaug import augmenters as iaa\n","\n","# Root directory of the project\n","ROOT_DIR = os.getcwd()\n","ROOT_DIR = ROOT_DIR+\"/Mask_r_cnn/\"\n","\n","MAMOGRAM_IMAGE_DIR = \"/scans/pseudo_color_image\" #Path of the mammograms\n","MAMOGRAM_MASK_DIR = \"/scans/preprocessed_mask/\"# Path of the ground truth masks\n","\n","\n","# Import Mask RCNN\n","sys.path.append(ROOT_DIR) # To find local version of the library\n","from mrcnn.config import Config\n","from mrcnn import model as modellib, utils\n","\n","# Path to trained weights file\n","COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_balloon.h5\")\n","\n","# Directory to save logs and model checkpoints, if not provided\n","# through the command line argument --logs\n","DEFAULT_LOGS_DIR = os.path.join(\"/content/drive/MyDrive/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1/logs\")#Log directory for saving the weights\n","DEMO_SAVE_DIR = \"scans/seg_mask/\"# path to save the segmentation masks\n","#if not os.path.exists(DEMO_SAVE_DIR):        \n","#    os.mkdir(DEMO_SAVE_DIR)\n","\n","############################################################\n","#  Configurations\n","############################################################\n","\n","\n","class MamogramConfig(Config):\n","    \"\"\"Configuration for training on the toy  dataset.\n","    Derives from the base Config class and overrides some values.\n","    \"\"\"\n","    # Give the configuration a recognizable name\n","    NAME = \"mamogram\"\n","\n","    # We use a GPU with 12GB memory, which can fit two images.\n","    # Adjust down if you use a smaller GPU.\n","    IMAGES_PER_GPU = 1\n","\n","    # Number of classes (including background)\n","    NUM_CLASSES = 1 + 1  # Background + lesion\n","\n","    # Number of training steps per epoch,set to the number of training data here\n","    STEPS_PER_EPOCH = 100\n","\n","    # Number of validation steps after each round of training\n","    VALIDATION_STEPS = 10\n","    # Resize mode: \"none\" or \"square\"\n","\n","    IMAGE_RESIZE_MODE = \"square\"\n","    IMAGE_MIN_DIM = 1024\n","    IMAGE_MAX_DIM = 1024\n","\n","    # Skip detections with < DETECTION_MIN_CONFIDENCE\n","    DETECTION_MIN_CONFIDENCE = 0.965 # alter this during testing to generate different TPR at different FPI\n","    # 0.7 0.75 0.8 0.85 0.9 \n","\n","############################################################\n","#  Dataset\n","############################################################\n","\n","class MamogramDataset(utils.Dataset):\n","\n","    def load_mamogram(self, subset):\n","        \"\"\"This method loads the actual image\n","        subset is either \"train\" or \"val\" depending on whether the image is part of the training or validation datasets \n","        \"\"\"\n","        # Add classes. We have only one class to add.\n","        # These are the things that will be segmented\n","        self.add_class(\"mamogram\", 1, \"lesion\")\n","\n","        # Train or validation dataset?\n","        #list all the files in the directory with the mamogram images\n","        files = os.listdir(ROOT_DIR + MAMOGRAM_IMAGE_DIR + subset )\n","        for fname in files:\n","            self.add_image(\"mamogram\", image_id=fname, path=ROOT_DIR + MAMOGRAM_IMAGE_DIR + subset + fname, subset=subset, fname=fname)\n","\n","\n","    def load_mask(self, image_id):\n","        \"\"\"load the instance masks for an image.\n","        Returns:\n","        a tuple containing:\n","        masks: A bool array of shape [height, width, instance count] with\n","        one mask per instance.\n","        class_ids: a 1D array of class IDs of the instance masks.\n","\n","        use dtype=np.int32\n","        \"\"\"\n","        info = self.image_info[image_id]\n","        fname = info['fname']\n","       \n","\n","        files = glob.glob(ROOT_DIR + MAMOGRAM_MASK_DIR + info['subset'] + fname[0:-4] + \"*\")\n","\n","        masks = []\n","        for i in range(0, len(files)):\n","            data = skimage.io.imread(files[i])\n","            \n","            if data.ndim != 1:\n","                data = skimage.color.rgb2gray(data)\n","          \n","            singleMask = data\n","            if i == 0:\n","                masks = np.zeros((singleMask.shape[0], singleMask.shape[1], len(files)))\n","            masks[:,:,i] = singleMask\n","\n","\n","        instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32)) #this is VERY important: array of class ids in the order that they appear in bigdata\n","        # Return mask, and array of class IDs of each instance. Since we have\n","        # one class ID only, we return an array of 1s\n","\n","        return (masks.astype(np.bool), instanceMaskMap)\n","\n","    def load_image(self, image_id):\n","        \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n","\t\tTaken from utils.py, any refinements we need can be done here\n","        \"\"\"\n","        # Load image\n","        image = skimage.io.imread(self.image_info[image_id]['path'])\n","        # If grayscale. Convert to RGB for consistency.\n","        if image.ndim != 3:\n","            image = skimage.color.gray2rgb(image)\n","        # If has an alpha channel, remove it for consistency\n","        if image.shape[-1] == 4:\n","            image = image[..., :3]\n","        return image\n","\n","    def image_reference(self, image_id):\n","        \"\"\"Return the path of the image.\"\"\"\n","        info = self.image_info[image_id]\n","        return info[\"path\"]\n","\n","\n","def train(model):\n","    \"\"\"Train the model.\"\"\"\n","    # Training dataset.\n","    dataset_train = MamogramDataset()\n","    dataset_train.load_mamogram(\"/train/\")\n","    dataset_train.prepare()\n","\n","    # Validation dataset\n","    dataset_val = MamogramDataset()\n","    dataset_val.load_mamogram(\"/val/\")\n","    dataset_val.prepare()\n","\n","    # Image augmentation\n","    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n","    aug = iaa.Sequential([\n","        iaa.OneOf([iaa.Fliplr(0.5),\n","                   iaa.Flipud(0.5),\n","                   iaa.Affine(rotate=90),\n","                   iaa.Affine(rotate=180),\n","                   iaa.Affine(rotate=270)]),\n","    ])\n","\n","    # *** This training schedule is an example. Update to your needs ***\n","    # Since we're using a very small dataset, and starting from\n","    # COCO trained weights, we don't need to train too long. Also,\n","    # no need to train all layers, just the heads should do it.\n","    print(\"Training network heads\")\n","\n","    model.train(dataset_train, dataset_val,\n","                learning_rate=config.LEARNING_RATE,\n","                epochs=10,augmentation=aug,\n","                layers='all')\n","    \n","def segment(model, imPath):\n","    \n","    image = skimage.io.imread(imPath)\n","\n","    fname = imPath.split('/')[-1]\n","    mrcnnData = model.detect([image], verbose=1)\n","       # documentation for model.detect:\n","       # \"\"\"Runs the detection pipeline.\n","\n","       # images: List of images, potentially of different sizes.\n","\n","       # Returns a list of dicts, one dict per image. The dict contains:\n","       # rois: [N, (y1, x1, y2, x2)] detection bounding boxes\n","       # class_ids: [N] int class IDs\n","       # scores: [N] float probability scores for the class IDs\n","       # masks: [H, W, N] instance binary masks\n","       # \"\"\"\n","\n","    mrcnnData = mrcnnData[0] #model.detect takes a list of images, but here we only provide one image so the output is a list with just one element\n","\n","    masks = mrcnnData['masks']\n","    for i in range(0, masks.shape[2]):\n","        #iterate through the masks\n","        maskSingle = np.squeeze(masks[:, :, i])\n","        file_name = DEMO_SAVE_DIR + \"demo_mask_\" + str(i) + \"_\" + fname + \"_{:%Y%m%dT%H%M%S}.png\".format(datetime.datetime.now())\n","        \n","\n","        scipy.misc.imsave(file_name, maskSingle.astype(np.int64)) \n","\n","\n","    print(mrcnnData)\n","    print(\"&&&&&&&&&&&: \"+str(mrcnnData['rois']))\n","    print(\"&&&&&&&&&&&: \"+str(mrcnnData['class_ids']))\n","    print(\"&&&&&&&&&&&: \"+str(mrcnnData['scores']))\n","\n","    return\n","\n","def segmentWrapper(model, directory):\n","    \"\"\"wrapper function for segment to take many images as an input, calls segment() on everything in the directory\"\"\"\n","    files = os.listdir(directory)\n","    for f in files:\n","        segment(model, directory + '/' + f)\n","\n","def overlayResult(image, mask):\n","\t\"\"\"Function to overlay segmentation mask on an image.\n","\tusage: image_var = overlayResult(image, dict['masks'] || masks_var)\n","\t\n","\timage: RGB or grayscale image [height, width, 1 || 3].\n","\tmask: segmentation mask [height, width, instance_count]\n","\t\n","\treturns resulting image.\n","\t\"\"\"\n","\t# Image is already in grayscale so we skip converting it\n","\t# May need to create 3 dimensions if single dimension image though so\n","\t# will add this as a placeholder\n","\tgray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n","\t# Copy color pixels from the original color image where mask is set\n","\tif mask.shape[-1] > 0:\n","\t\t#collapse masks into one layer\n","\t\tmask = (np.sum(mask, -1, keepdims=True) >= 1)\n","\t\toverlay = np.where(mask, image, gray).astype(np.uint8)\n","\telse:\n","\t\toverlay = gray.astype(np.uint8)\n","\t\t\n","\treturn overlay\n","\t\n","config = MamogramConfig()\n","\n","model = modellib.MaskRCNN(mode=\"training\", config=config,\n","                                  model_dir=DEFAULT_LOGS_DIR)\n","\n","weights_path = \"/content/drive/MyDrive/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1/mask_rcnn_balloon.h5\"\n","\n","model.load_weights(weights_path, by_name=True)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-832c660bf6f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m model = modellib.MaskRCNN(mode=\"training\", config=config,\n\u001b[0;32m--> 250\u001b[0;31m                                   model_dir=DEFAULT_LOGS_DIR)\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0mweights_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1/mask_rcnn_balloon.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1/Mask_r_cnn/mrcnn/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mode, config, model_dir)\u001b[0m\n\u001b[1;32m   1835\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_log_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1837\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1839\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1/Mask_r_cnn/mrcnn/model.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, mode, config)\u001b[0m\n\u001b[1;32m   1874\u001b[0m             \u001b[0;31m# Normalize coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m             gt_boxes = KL.Lambda(lambda x: norm_boxes_graph(\n\u001b[0;32m-> 1876\u001b[0;31m                 x, K.shape(input_image)[1:3]))(input_gt_boxes)\n\u001b[0m\u001b[1;32m   1877\u001b[0m             \u001b[0;31m# 3. GT Masks (zero padded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m             \u001b[0;31m# [batch, height, width, MAX_GT_INSTANCES]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    867\u001b[0m                               build_graph=False)\n\u001b[1;32m    868\u001b[0m       outputs = nest.map_structure(\n\u001b[0;32m--> 869\u001b[0;31m           keras_tensor.keras_tensor_from_tensor, outputs)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_set_inputs'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36mkeras_tensor_from_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_tensor_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36mfrom_tensor\u001b[0;34m(cls, tensor)\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Fallback to the generic arbitrary-typespec KerasTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mtype_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_spec_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m   raise TypeError(\"Could not build a TypeSpec for %r with type %s\" %\n\u001b[0;32m--> 554\u001b[0;31m                   (value, type(value).__name__))\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Could not build a TypeSpec for <KerasTensor: shape=(None, None, 4) dtype=float32 (created by layer 'tf.math.truediv_2')> with type KerasTensor"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLX2dhnQbSXx","executionInfo":{"status":"ok","timestamp":1616357743024,"user_tz":-360,"elapsed":881,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"9afc0546-fe50-4405-8a6f-22ad1786204d"},"source":["%cd \"/content/drive/MyDrive/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8LkzfdocbZXc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"HrpQKGeSPnLS","executionInfo":{"status":"error","timestamp":1616357813859,"user_tz":-360,"elapsed":66109,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"f4c03f50-ccfe-43a2-e08c-c3837396649c"},"source":["train(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training network heads\n","\n","Starting at epoch 0. LR=0.001\n","\n","Checkpoint Path: ROOT_DIR/logs/mamogram20210321T2014/mask_rcnn_mamogram_{epoch:04d}.h5\n","Selecting layers to train\n","conv1                  (Conv2D)\n","bn_conv1               (BatchNorm)\n","res2a_branch2a         (Conv2D)\n","bn2a_branch2a          (BatchNorm)\n","res2a_branch2b         (Conv2D)\n","bn2a_branch2b          (BatchNorm)\n","res2a_branch2c         (Conv2D)\n","res2a_branch1          (Conv2D)\n","bn2a_branch2c          (BatchNorm)\n","bn2a_branch1           (BatchNorm)\n","res2b_branch2a         (Conv2D)\n","bn2b_branch2a          (BatchNorm)\n","res2b_branch2b         (Conv2D)\n","bn2b_branch2b          (BatchNorm)\n","res2b_branch2c         (Conv2D)\n","bn2b_branch2c          (BatchNorm)\n","res2c_branch2a         (Conv2D)\n","bn2c_branch2a          (BatchNorm)\n","res2c_branch2b         (Conv2D)\n","bn2c_branch2b          (BatchNorm)\n","res2c_branch2c         (Conv2D)\n","bn2c_branch2c          (BatchNorm)\n","res3a_branch2a         (Conv2D)\n","bn3a_branch2a          (BatchNorm)\n","res3a_branch2b         (Conv2D)\n","bn3a_branch2b          (BatchNorm)\n","res3a_branch2c         (Conv2D)\n","res3a_branch1          (Conv2D)\n","bn3a_branch2c          (BatchNorm)\n","bn3a_branch1           (BatchNorm)\n","res3b_branch2a         (Conv2D)\n","bn3b_branch2a          (BatchNorm)\n","res3b_branch2b         (Conv2D)\n","bn3b_branch2b          (BatchNorm)\n","res3b_branch2c         (Conv2D)\n","bn3b_branch2c          (BatchNorm)\n","res3c_branch2a         (Conv2D)\n","bn3c_branch2a          (BatchNorm)\n","res3c_branch2b         (Conv2D)\n","bn3c_branch2b          (BatchNorm)\n","res3c_branch2c         (Conv2D)\n","bn3c_branch2c          (BatchNorm)\n","res3d_branch2a         (Conv2D)\n","bn3d_branch2a          (BatchNorm)\n","res3d_branch2b         (Conv2D)\n","bn3d_branch2b          (BatchNorm)\n","res3d_branch2c         (Conv2D)\n","bn3d_branch2c          (BatchNorm)\n","res4a_branch2a         (Conv2D)\n","bn4a_branch2a          (BatchNorm)\n","res4a_branch2b         (Conv2D)\n","bn4a_branch2b          (BatchNorm)\n","res4a_branch2c         (Conv2D)\n","res4a_branch1          (Conv2D)\n","bn4a_branch2c          (BatchNorm)\n","bn4a_branch1           (BatchNorm)\n","res4b_branch2a         (Conv2D)\n","bn4b_branch2a          (BatchNorm)\n","res4b_branch2b         (Conv2D)\n","bn4b_branch2b          (BatchNorm)\n","res4b_branch2c         (Conv2D)\n","bn4b_branch2c          (BatchNorm)\n","res4c_branch2a         (Conv2D)\n","bn4c_branch2a          (BatchNorm)\n","res4c_branch2b         (Conv2D)\n","bn4c_branch2b          (BatchNorm)\n","res4c_branch2c         (Conv2D)\n","bn4c_branch2c          (BatchNorm)\n","res4d_branch2a         (Conv2D)\n","bn4d_branch2a          (BatchNorm)\n","res4d_branch2b         (Conv2D)\n","bn4d_branch2b          (BatchNorm)\n","res4d_branch2c         (Conv2D)\n","bn4d_branch2c          (BatchNorm)\n","res4e_branch2a         (Conv2D)\n","bn4e_branch2a          (BatchNorm)\n","res4e_branch2b         (Conv2D)\n","bn4e_branch2b          (BatchNorm)\n","res4e_branch2c         (Conv2D)\n","bn4e_branch2c          (BatchNorm)\n","res4f_branch2a         (Conv2D)\n","bn4f_branch2a          (BatchNorm)\n","res4f_branch2b         (Conv2D)\n","bn4f_branch2b          (BatchNorm)\n","res4f_branch2c         (Conv2D)\n","bn4f_branch2c          (BatchNorm)\n","res4g_branch2a         (Conv2D)\n","bn4g_branch2a          (BatchNorm)\n","res4g_branch2b         (Conv2D)\n","bn4g_branch2b          (BatchNorm)\n","res4g_branch2c         (Conv2D)\n","bn4g_branch2c          (BatchNorm)\n","res4h_branch2a         (Conv2D)\n","bn4h_branch2a          (BatchNorm)\n","res4h_branch2b         (Conv2D)\n","bn4h_branch2b          (BatchNorm)\n","res4h_branch2c         (Conv2D)\n","bn4h_branch2c          (BatchNorm)\n","res4i_branch2a         (Conv2D)\n","bn4i_branch2a          (BatchNorm)\n","res4i_branch2b         (Conv2D)\n","bn4i_branch2b          (BatchNorm)\n","res4i_branch2c         (Conv2D)\n","bn4i_branch2c          (BatchNorm)\n","res4j_branch2a         (Conv2D)\n","bn4j_branch2a          (BatchNorm)\n","res4j_branch2b         (Conv2D)\n","bn4j_branch2b          (BatchNorm)\n","res4j_branch2c         (Conv2D)\n","bn4j_branch2c          (BatchNorm)\n","res4k_branch2a         (Conv2D)\n","bn4k_branch2a          (BatchNorm)\n","res4k_branch2b         (Conv2D)\n","bn4k_branch2b          (BatchNorm)\n","res4k_branch2c         (Conv2D)\n","bn4k_branch2c          (BatchNorm)\n","res4l_branch2a         (Conv2D)\n","bn4l_branch2a          (BatchNorm)\n","res4l_branch2b         (Conv2D)\n","bn4l_branch2b          (BatchNorm)\n","res4l_branch2c         (Conv2D)\n","bn4l_branch2c          (BatchNorm)\n","res4m_branch2a         (Conv2D)\n","bn4m_branch2a          (BatchNorm)\n","res4m_branch2b         (Conv2D)\n","bn4m_branch2b          (BatchNorm)\n","res4m_branch2c         (Conv2D)\n","bn4m_branch2c          (BatchNorm)\n","res4n_branch2a         (Conv2D)\n","bn4n_branch2a          (BatchNorm)\n","res4n_branch2b         (Conv2D)\n","bn4n_branch2b          (BatchNorm)\n","res4n_branch2c         (Conv2D)\n","bn4n_branch2c          (BatchNorm)\n","res4o_branch2a         (Conv2D)\n","bn4o_branch2a          (BatchNorm)\n","res4o_branch2b         (Conv2D)\n","bn4o_branch2b          (BatchNorm)\n","res4o_branch2c         (Conv2D)\n","bn4o_branch2c          (BatchNorm)\n","res4p_branch2a         (Conv2D)\n","bn4p_branch2a          (BatchNorm)\n","res4p_branch2b         (Conv2D)\n","bn4p_branch2b          (BatchNorm)\n","res4p_branch2c         (Conv2D)\n","bn4p_branch2c          (BatchNorm)\n","res4q_branch2a         (Conv2D)\n","bn4q_branch2a          (BatchNorm)\n","res4q_branch2b         (Conv2D)\n","bn4q_branch2b          (BatchNorm)\n","res4q_branch2c         (Conv2D)\n","bn4q_branch2c          (BatchNorm)\n","res4r_branch2a         (Conv2D)\n","bn4r_branch2a          (BatchNorm)\n","res4r_branch2b         (Conv2D)\n","bn4r_branch2b          (BatchNorm)\n","res4r_branch2c         (Conv2D)\n","bn4r_branch2c          (BatchNorm)\n","res4s_branch2a         (Conv2D)\n","bn4s_branch2a          (BatchNorm)\n","res4s_branch2b         (Conv2D)\n","bn4s_branch2b          (BatchNorm)\n","res4s_branch2c         (Conv2D)\n","bn4s_branch2c          (BatchNorm)\n","res4t_branch2a         (Conv2D)\n","bn4t_branch2a          (BatchNorm)\n","res4t_branch2b         (Conv2D)\n","bn4t_branch2b          (BatchNorm)\n","res4t_branch2c         (Conv2D)\n","bn4t_branch2c          (BatchNorm)\n","res4u_branch2a         (Conv2D)\n","bn4u_branch2a          (BatchNorm)\n","res4u_branch2b         (Conv2D)\n","bn4u_branch2b          (BatchNorm)\n","res4u_branch2c         (Conv2D)\n","bn4u_branch2c          (BatchNorm)\n","res4v_branch2a         (Conv2D)\n","bn4v_branch2a          (BatchNorm)\n","res4v_branch2b         (Conv2D)\n","bn4v_branch2b          (BatchNorm)\n","res4v_branch2c         (Conv2D)\n","bn4v_branch2c          (BatchNorm)\n","res4w_branch2a         (Conv2D)\n","bn4w_branch2a          (BatchNorm)\n","res4w_branch2b         (Conv2D)\n","bn4w_branch2b          (BatchNorm)\n","res4w_branch2c         (Conv2D)\n","bn4w_branch2c          (BatchNorm)\n","res5a_branch2a         (Conv2D)\n","bn5a_branch2a          (BatchNorm)\n","res5a_branch2b         (Conv2D)\n","bn5a_branch2b          (BatchNorm)\n","res5a_branch2c         (Conv2D)\n","res5a_branch1          (Conv2D)\n","bn5a_branch2c          (BatchNorm)\n","bn5a_branch1           (BatchNorm)\n","res5b_branch2a         (Conv2D)\n","bn5b_branch2a          (BatchNorm)\n","res5b_branch2b         (Conv2D)\n","bn5b_branch2b          (BatchNorm)\n","res5b_branch2c         (Conv2D)\n","bn5b_branch2c          (BatchNorm)\n","res5c_branch2a         (Conv2D)\n","bn5c_branch2a          (BatchNorm)\n","res5c_branch2b         (Conv2D)\n","bn5c_branch2b          (BatchNorm)\n","res5c_branch2c         (Conv2D)\n","bn5c_branch2c          (BatchNorm)\n","fpn_c5p5               (Conv2D)\n","fpn_c4p4               (Conv2D)\n","fpn_c3p3               (Conv2D)\n","fpn_c2p2               (Conv2D)\n","fpn_p5                 (Conv2D)\n","fpn_p2                 (Conv2D)\n","fpn_p3                 (Conv2D)\n","fpn_p4                 (Conv2D)\n","In model:  rpn_model\n","    rpn_conv_shared        (Conv2D)\n","    rpn_class_raw          (Conv2D)\n","    rpn_bbox_pred          (Conv2D)\n","mrcnn_mask_conv1       (TimeDistributed)\n","mrcnn_mask_bn1         (TimeDistributed)\n","mrcnn_mask_conv2       (TimeDistributed)\n","mrcnn_mask_bn2         (TimeDistributed)\n","mrcnn_class_conv1      (TimeDistributed)\n","mrcnn_class_bn1        (TimeDistributed)\n","mrcnn_mask_conv3       (TimeDistributed)\n","mrcnn_mask_bn3         (TimeDistributed)\n","mrcnn_class_conv2      (TimeDistributed)\n","mrcnn_class_bn2        (TimeDistributed)\n","mrcnn_mask_conv4       (TimeDistributed)\n","mrcnn_mask_bn4         (TimeDistributed)\n","mrcnn_bbox_fc          (TimeDistributed)\n","mrcnn_mask_deconv      (TimeDistributed)\n","mrcnn_class_logits     (TimeDistributed)\n","mrcnn_mask             (TimeDistributed)\n"],"name":"stdout"},{"output_type":"stream","text":["ERROR:root:Error processing image {'id': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'source': 'mamogram', 'path': '/content/drive/MyDrive/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1/scans/pseudo_color_image/train/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'subset': '/train/', 'fname': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png'}\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MaskRCNN-main/mrcnn/model.py\", line 1709, in data_generator\n","    use_mini_mask=config.USE_MINI_MASK)\n","  File \"/content/drive/MyDrive/MaskRCNN-main/mrcnn/model.py\", line 1212, in load_image_gt\n","    mask, class_ids = dataset.load_mask(image_id)\n","  File \"<ipython-input-45-729ee543eb9f>\", line 122, in load_mask\n","    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32)) #this is VERY important: array of class ids in the order that they appear in bigdata\n","AttributeError: 'list' object has no attribute 'shape'\n","ERROR:root:Error processing image {'id': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'source': 'mamogram', 'path': '/content/drive/MyDrive/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1/scans/pseudo_color_image/train/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'subset': '/train/', 'fname': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png'}\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MaskRCNN-main/mrcnn/model.py\", line 1709, in data_generator\n","    use_mini_mask=config.USE_MINI_MASK)\n","  File \"/content/drive/MyDrive/MaskRCNN-main/mrcnn/model.py\", line 1212, in load_image_gt\n","    mask, class_ids = dataset.load_mask(image_id)\n","  File \"<ipython-input-45-729ee543eb9f>\", line 122, in load_mask\n","    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32)) #this is VERY important: array of class ids in the order that they appear in bigdata\n","AttributeError: 'list' object has no attribute 'shape'\n","ERROR:root:Error processing image {'id': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'source': 'mamogram', 'path': '/content/drive/MyDrive/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1/scans/pseudo_color_image/train/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'subset': '/train/', 'fname': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png'}\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MaskRCNN-main/mrcnn/model.py\", line 1709, in data_generator\n","    use_mini_mask=config.USE_MINI_MASK)\n","  File \"/content/drive/MyDrive/MaskRCNN-main/mrcnn/model.py\", line 1212, in load_image_gt\n","    mask, class_ids = dataset.load_mask(image_id)\n","  File \"<ipython-input-45-729ee543eb9f>\", line 122, in load_mask\n","    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32)) #this is VERY important: array of class ids in the order that they appear in bigdata\n","AttributeError: 'list' object has no attribute 'shape'\n","ERROR:root:Error processing image {'id': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'source': 'mamogram', 'path': '/content/drive/MyDrive/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1/scans/pseudo_color_image/train/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'subset': '/train/', 'fname': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png'}\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MaskRCNN-main/mrcnn/model.py\", line 1709, in data_generator\n","    use_mini_mask=config.USE_MINI_MASK)\n","  File \"/content/drive/MyDrive/MaskRCNN-main/mrcnn/model.py\", line 1212, in load_image_gt\n","    mask, class_ids = dataset.load_mask(image_id)\n","  File \"<ipython-input-45-729ee543eb9f>\", line 122, in load_mask\n","    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32)) #this is VERY important: array of class ids in the order that they appear in bigdata\n","AttributeError: 'list' object has no attribute 'shape'\n","ERROR:root:Error processing image {'id': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'source': 'mamogram', 'path': '/content/drive/MyDrive/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1/scans/pseudo_color_image/train/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'subset': '/train/', 'fname': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png'}\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MaskRCNN-main/mrcnn/model.py\", line 1709, in data_generator\n","    use_mini_mask=config.USE_MINI_MASK)\n","  File \"/content/drive/MyDrive/MaskRCNN-main/mrcnn/model.py\", line 1212, in load_image_gt\n","    mask, class_ids = dataset.load_mask(image_id)\n","  File \"<ipython-input-45-729ee543eb9f>\", line 122, in load_mask\n","    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32)) #this is VERY important: array of class ids in the order that they appear in bigdata\n","AttributeError: 'list' object has no attribute 'shape'\n","ERROR:root:Error processing image {'id': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'source': 'mamogram', 'path': '/content/drive/MyDrive/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN-1/scans/pseudo_color_image/train/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'subset': '/train/', 'fname': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png'}\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/MaskRCNN-main/mrcnn/model.py\", line 1709, in data_generator\n","    use_mini_mask=config.USE_MINI_MASK)\n","  File \"/content/drive/MyDrive/MaskRCNN-main/mrcnn/model.py\", line 1212, in load_image_gt\n","    mask, class_ids = dataset.load_mask(image_id)\n","  File \"<ipython-input-45-729ee543eb9f>\", line 122, in load_mask\n","    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32)) #this is VERY important: array of class ids in the order that they appear in bigdata\n","AttributeError: 'list' object has no attribute 'shape'\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 677, in _data_generator_task\n","    generator_output = next(self._generator)\n","  File \"/content/drive/MyDrive/MaskRCNN-main/mrcnn/model.py\", line 1709, in data_generator\n","    use_mini_mask=config.USE_MINI_MASK)\n","  File \"/content/drive/MyDrive/MaskRCNN-main/mrcnn/model.py\", line 1212, in load_image_gt\n","    mask, class_ids = dataset.load_mask(image_id)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n"],"name":"stdout"},{"output_type":"stream","text":["  File \"<ipython-input-45-729ee543eb9f>\", line 122, in load_mask\n","    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32)) #this is VERY important: array of class ids in the order that they appear in bigdata\n","AttributeError: 'list' object has no attribute 'shape'\n"],"name":"stderr"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-9d3046b5d0d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-45-729ee543eb9f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                 layers='all')\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/MaskRCNN-main/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2372\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2374\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2375\u001b[0m         )\n\u001b[1;32m   2376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2190\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2191\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"]}]},{"cell_type":"code","metadata":{"id":"FTeoV3cLANif"},"source":["!pip install keras==2.1.5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U6iX6Ww5APpH"},"source":["!pip install tensorflow==1.14.0\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ejkjZ_NaAJQj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OZ_NENoPAZdr"},"source":["\"\"\"\n","Original code: \n","    \n","Mask R-CNN\n","Train on the toy Balloon dataset and implement color splash effect.\n","\n","Copyright (c) 2018 Matterport, Inc.\n","Licensed under the MIT License (see LICENSE for details)\n","Written by Waleed Abdulla\n","\n","------------------------------------------------------------\n","Adapted for mammographic mass detection and segmentation.\n","\n","\n","\"\"\"\n","\n","import os\n","import sys\n","import json\n","import datetime\n","import numpy as np\n","import skimage.draw\n","import matplotlib.image\n","import glob\n","import scipy.misc\n","from PIL import Image\n","#import imgaug \n","from imgaug import augmenters as iaa\n","\n","# Root directory of the project\n","ROOT_DIR = os.getcwd()\n","ROOT_DIR = ROOT_DIR+\"/Mask_r_cnn/\"\n","\n","MAMOGRAM_IMAGE_DIR = \"/scans/pseudo_color_image/\" #Path of the mammograms\n","MAMOGRAM_MASK_DIR = \"/scans/preprocessed_mask/\"# Path of the ground truth masks\n","\n","\n","# Import Mask RCNN\n","sys.path.append(ROOT_DIR) # To find local version of the library\n","from mrcnn.config import Config\n","from mrcnn import model as modellib, utils\n","\n","# Path to trained weights file\n","COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_balloon.h5\")\n","\n","# Directory to save logs and model checkpoints, if not provided\n","# through the command line argument --logs\n","DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")#Log directory for saving the weights\n","DEMO_SAVE_DIR = \"scans/seg_mask/\"# path to save the segmentation masks\n","if not os.path.exists(DEMO_SAVE_DIR):        \n","    os.mkdir(DEMO_SAVE_DIR)\n","\n","############################################################\n","#  Configurations\n","############################################################\n","\n","\n","class MamogramConfig(Config):\n","    \"\"\"Configuration for training on the toy  dataset.\n","    Derives from the base Config class and overrides some values.\n","    \"\"\"\n","    # Give the configuration a recognizable name\n","    NAME = \"mamogram\"\n","\n","    # We use a GPU with 12GB memory, which can fit two images.\n","    # Adjust down if you use a smaller GPU.\n","    IMAGES_PER_GPU = 1\n","\n","    # Number of classes (including background)\n","    NUM_CLASSES = 1 + 1  # Background + lesion\n","\n","    # Number of training steps per epoch,set to the number of training data here\n","    STEPS_PER_EPOCH = 100\n","\n","    # Number of validation steps after each round of training\n","    VALIDATION_STEPS = 10\n","    # Resize mode: \"none\" or \"square\"\n","\n","    IMAGE_RESIZE_MODE = \"square\"\n","    IMAGE_MIN_DIM = 1024\n","    IMAGE_MAX_DIM = 1024\n","\n","    # Skip detections with < DETECTION_MIN_CONFIDENCE\n","    DETECTION_MIN_CONFIDENCE = 0.965 # alter this during testing to generate different TPR at different FPI\n","    # 0.7 0.75 0.8 0.85 0.9 \n","\n","\n","############################################################\n","#  Dataset\n","############################################################\n","\n","class MamogramDataset(utils.Dataset):\n","\n","    def load_mamogram(self, subset):\n","        \"\"\"This method loads the actual image\n","        subset is either \"train\" or \"val\" depending on whether the image is part of the training or validation datasets \n","        \"\"\"\n","        # Add classes. We have only one class to add.\n","        # These are the things that will be segmented\n","        self.add_class(\"mamogram\", 1, \"lesion\")\n","\n","        # Train or validation dataset?\n","\n","        #list all the files in the directory with the mamogram images\n","        files = os.listdir(ROOT_DIR + MAMOGRAM_IMAGE_DIR + subset + \"/\")\n","\n","        for fname in files:\n","            self.add_image(\"mamogram\", image_id=fname, path=ROOT_DIR + MAMOGRAM_IMAGE_DIR + subset +\"/\"+ fname, subset=subset, fname=fname)\n","\n","\n","    def load_mask(self, image_id):\n","        \"\"\"load the instance masks for an image.\n","        Returns:\n","        a tuple containing:\n","        masks: A bool array of shape [height, width, instance count] with\n","        one mask per instance.\n","        class_ids: a 1D array of class IDs of the instance masks.\n","\n","        use dtype=np.int32\n","        \"\"\"\n","        info = self.image_info[image_id]\n","        fname = info['fname']\n","       \n","\n","        files = glob.glob(ROOT_DIR + MAMOGRAM_MASK_DIR + info['subset'] + fname[0:-4] + \"*\")\n","\n","        masks = []\n","        for i in range(0, len(files)):\n","            data = skimage.io.imread(files[i])\n","            \n","            if data.ndim != 1:\n","                data = skimage.color.rgb2gray(data)\n","          \n","            singleMask = data\n","            if i == 0:\n","                masks = np.zeros((singleMask.shape[0], singleMask.shape[1], len(files)))\n","            masks[:,:,i] = singleMask\n","\n"," \n","\n","        instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32)) #this is VERY important: array of class ids in the order that they appear in bigdata\n","        # Return mask, and array of class IDs of each instance. Since we have\n","        # one class ID only, we return an array of 1s\n","\n","        return (masks.astype(np.bool), instanceMaskMap)\n","\n","    def load_image(self, image_id):\n","        \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n","\t\tTaken from utils.py, any refinements we need can be done here\n","        \"\"\"\n","        # Load image\n","        image = skimage.io.imread(self.image_info[image_id]['path'])\n","        # If grayscale. Convert to RGB for consistency.\n","        if image.ndim != 3:\n","            image = skimage.color.gray2rgb(image)\n","        # If has an alpha channel, remove it for consistency\n","        if image.shape[-1] == 4:\n","            image = image[..., :3]\n","        return image\n","\n","    def image_reference(self, image_id):\n","        \"\"\"Return the path of the image.\"\"\"\n","        info = self.image_info[image_id]\n","        return info[\"path\"]\n","\n","\n","def train(model):\n","    \"\"\"Train the model.\"\"\"\n","    # Training dataset.\n","    dataset_train = MamogramDataset()\n","    dataset_train.load_mamogram(\"/train/\")\n","    dataset_train.prepare()\n","\n","    # Validation dataset\n","    dataset_val = MamogramDataset()\n","    dataset_val.load_mamogram(\"/val/\")\n","    dataset_val.prepare()\n","\n","    # Image augmentation\n","    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n","    aug = iaa.Sequential([\n","        iaa.OneOf([iaa.Fliplr(0.5),\n","                   iaa.Flipud(0.5),\n","                   iaa.Affine(rotate=90),\n","                   iaa.Affine(rotate=180),\n","                   iaa.Affine(rotate=270)]),\n","    ])\n","\n","    # *** This training schedule is an example. Update to your needs ***\n","    # Since we're using a very small dataset, and starting from\n","    # COCO trained weights, we don't need to train too long. Also,\n","    # no need to train all layers, just the heads should do it.\n","    print(\"Training network heads\")\n","\n","    model.train(dataset_train, dataset_val,\n","                learning_rate=config.LEARNING_RATE,\n","                epochs=10,augmentation=aug,\n","                layers='all')\n","\n","def segment(model, imPath):\n","    \n","    image = skimage.io.imread(imPath)\n","\n","    fname = imPath.split('/')[-1]\n","    mrcnnData = model.detect([image], verbose=1)\n","       # documentation for model.detect:\n","       # \"\"\"Runs the detection pipeline.\n","\n","       # images: List of images, potentially of different sizes.\n","\n","       # Returns a list of dicts, one dict per image. The dict contains:\n","       # rois: [N, (y1, x1, y2, x2)] detection bounding boxes\n","       # class_ids: [N] int class IDs\n","       # scores: [N] float probability scores for the class IDs\n","       # masks: [H, W, N] instance binary masks\n","       # \"\"\"\n","\n","    mrcnnData = mrcnnData[0] #model.detect takes a list of images, but here we only provide one image so the output is a list with just one element\n","\n","    masks = mrcnnData['masks']\n","    for i in range(0, masks.shape[2]):\n","        #iterate through the masks\n","        maskSingle = np.squeeze(masks[:, :, i])\n","        file_name = DEMO_SAVE_DIR + \"demo_mask_\" + str(i) + \"_\" + fname + \"_{:%Y%m%dT%H%M%S}.png\".format(datetime.datetime.now())\n","        \n","\n","        scipy.misc.imsave(file_name, maskSingle.astype(np.int64)) \n","\n","\n","    print(mrcnnData)\n","    print(\"&&&&&&&&&&&: \"+str(mrcnnData['rois']))\n","    print(\"&&&&&&&&&&&: \"+str(mrcnnData['class_ids']))\n","    print(\"&&&&&&&&&&&: \"+str(mrcnnData['scores']))\n","\n","    return\n","\n","def segmentWrapper(model, directory):\n","    \"\"\"wrapper function for segment to take many images as an input, calls segment() on everything in the directory\"\"\"\n","    files = os.listdir(directory)\n","    for f in files:\n","        segment(model, directory + '/' + f)\n","\n","def overlayResult(image, mask):\n","\t\"\"\"Function to overlay segmentation mask on an image.\n","\tusage: image_var = overlayResult(image, dict['masks'] || masks_var)\n","\t\n","\timage: RGB or grayscale image [height, width, 1 || 3].\n","\tmask: segmentation mask [height, width, instance_count]\n","\t\n","\treturns resulting image.\n","\t\"\"\"\n","\t# Image is already in grayscale so we skip converting it\n","\t# May need to create 3 dimensions if single dimension image though so\n","\t# will add this as a placeholder\n","\tgray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n","\t# Copy color pixels from the original color image where mask is set\n","\tif mask.shape[-1] > 0:\n","\t\t#collapse masks into one layer\n","\t\tmask = (np.sum(mask, -1, keepdims=True) >= 1)\n","\t\toverlay = np.where(mask, image, gray).astype(np.uint8)\n","\telse:\n","\t\toverlay = gray.astype(np.uint8)\n","\t\t\n","\treturn overlay\n","\t\n","\t\n","############################################################\n","#  Training\n","############################################################\n","\n","if __name__ == '__main__':\n","    import argparse\n","\n","    # Parse command line arguments\n","    parser = argparse.ArgumentParser(\n","        description='Train Mask R-CNN to detect breast lesions.')\n","    parser.add_argument(\"command\",\n","                        metavar=\"<command>\",\n","                        help=\"'train' or 'segment'\")\n","    parser.add_argument('--weights', required=True,\n","                        metavar=\"/path/to/weights.h5\",\n","                        help=\"Path to weights .h5 file or 'coco'\")\n","    parser.add_argument('--image', required=False,\n","                        metavar='/path/to/image',\n","                        help=\"Path to image file for segmentation\")\n","    args = parser.parse_args()\n","\n","    # Configurations\n","    if args.command == \"train\":\n","        config = MamogramConfig()\n","    else:\n","        class InferenceConfig(MamogramConfig):\n","            # Set batch size to 1 since we'll be running inference on\n","            # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n","            GPU_COUNT = 1\n","            IMAGES_PER_GPU = 1\n","        config = InferenceConfig()\n","    config.display()\n","\n","    # Create model\n","    if args.command == \"train\":\n","        model = modellib.MaskRCNN(mode=\"training\", config=config,\n","                                  model_dir=DEFAULT_LOGS_DIR)\n","    else:\n","        model = modellib.MaskRCNN(mode=\"inference\", config=config,\n","                                  model_dir=DEFAULT_LOGS_DIR)\n","\n","    # Select weights file to load\n","    if args.weights.lower() == \"coco\":\n","        weights_path = COCO_WEIGHTS_PATH\n","        # Download weights file\n","        if not os.path.exists(weights_path):\n","            utils.download_trained_weights(weights_path)\n","    else:\n","        weights_path = args.weights\n","\n","    # Load weights\n","    print(\"Loading weights \", weights_path)\n","    if args.weights.lower() == \"coco\":\n","        # Exclude the last layers because they require a matching\n","        # number of classes  \n","        model.load_weights(weights_path, by_name=True, exclude=[\n","            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n","            \"mrcnn_bbox\", \"mrcnn_mask\"])\n","    else:\n","        model.load_weights(weights_path, by_name=True)\n","\n","    # Train or evaluate\n","    if args.command == \"train\":\n","        train(model)\n","    elif args.command == \"segment\":\n","        if os.path.isdir(args.image):\n","            segmentWrapper(model, args.image)\n","        else:\n","            segment(model, args.image)\n","    else:\n","        print(\"'{}' is not recognized. \"\n","              \"Use 'train' or 'segment'\".format(args.command))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NTVL6DVaAZiI"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eD23pWqwzMfB"},"source":["############ starting matlab codes  ###############"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":129},"id":"EGq1NbLyzMvf","executionInfo":{"status":"error","timestamp":1615664222581,"user_tz":-360,"elapsed":851,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"b3ff115a-b131-4b47-d307-e8dce5a79dfc"},"source":["#@mfunction(\"item_name\")\n","def Read_files_in_folder(path, mode):\n","    # Read_files_in_folder Summary of this function goes here\n","    #   Detailed explanation goes here\n","    # This is a fuction that reads the files/folders under a folder path\n","    #   INPUT   path   the folder path\n","    #           mode   whether the user want read files or folders\n","    #   OUTPUT  item_name    return the names of the items under the path\n","\n","    pt = (path)\n","\n","    item_name = {}\n","\n","    M = len(pt)\n","\n","    k = 0\n","# format(mstring('short'))\n","\n","\n","    for i in range(1,M): #mslice[1:M]:\n","        if (pt(i) == ('.')):\n","            continue\n","        else:\n","            k = k + 1\n","            item_name{k}== pt\n","        end\n","\n","    end\n","\n","#end"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-95-6ac73c35630a>\"\u001b[0;36m, line \u001b[0;32m27\u001b[0m\n\u001b[0;31m    item_name{k}== pt\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"id":"DSncFqL_65Ky","executionInfo":{"status":"error","timestamp":1615663954936,"user_tz":-360,"elapsed":837,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"dd8a1406-3a2b-4110-c6ec-af3eccacaf77"},"source":["image_path = 'scans\\\\preprocessed_image\\\\'\n","image_save_path = 'scans\\\\pseudo_color_image\\\\'\n","\n","\n","item_names = Read_files_in_folder(image_path, ('files'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["25\n","files\n"],"name":"stdout"},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-91-1b5d8b73e787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mitem_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRead_files_in_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-90-824f8ace3976>\u001b[0m in \u001b[0;36mRead_files_in_folder\u001b[0;34m(path, mode)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mitem_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"]}]},{"cell_type":"code","metadata":{"id":"aVIDaubbz-RE"},"source":["#@mfunction(\"len_bank\")\n","def Morphological_filter_bank(Num_scale=None, D=None, type=None):\n","    #Morphological_filter_bank Summary of this function goes here\n","    #   This function generates the length of the linear structuring elements (LSE) \n","    #   used in morphological filter elements on different scales. Either\n","    #   linear or logarithmic scale interval is used.\n","    #   INPUT     Num_scale  The number of scales used\n","    #             D          The diameter range of breast masses\n","    #             \n","    #             type       The scale type (linear or logarithmic)\n","    #   OUTPUT    len_bank    The magnitudes of the LSEs\n","\n","    if strcmp(type, mstring('linear')):\n","        scale_interval = ceil((D(2) - D(1)) / Num_scale)\n","        len_bank = zeros(1, Num_scale + 1)\n","        for l in mslice[1:Num_scale + 1]:\n","            len_bank(l).lvalue = D(1) + (l - 1) * scale_interval\n","        end\n","        # This is a linear bank\n","        len_bank(Num_scale + 1).lvalue = D(2)\n","\n","    end\n","\n","\n","    if strcmp(type, mstring('exponential')):\n","        scale_interval = (D(2) / D(1)) ** (1 / Num_scale)\n","        for l in mslice[1:Num_scale + 1]:\n","            len_bank(l).lvalue = round(D(1) * (scale_interval ** (l - 1)))\n","        end\n","        # This is a linear bank\n","        len_bank(Num_scale + 1).lvalue = D(2)\n","\n","    end\n","#end"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2OJfINqhz-Tx"},"source":["#@mfunction(\"enhanced_image\")\n","def Morphological_sifter(M1=None, M2=None, orientation=None, image=None, L_or_R=None, padding_option=None, breast_mask=None):#,rowmin,colmin\n","    # Summary of this function goes here\n","    #   Detailed explanation goes here\n","    # This is a function that does multi-scale morphological sifting used\n","    # linear structuring elements (LSE) with given length\n","    #INPUT  M1,M2: Length of the LSEs  M1>M2\n","    #       orientation: Orientations of the LSEs in degrees, it is a 1*N\n","    #       vector containing the angles of each LSE\n","    #       image: The input image to be processed\n","    #       L_or_R: Indicator of left or right breast\n","    #       padding_option: Image boundary padding options. \n","    #                       If set to 0, pad the boundary with highest\n","    #                       intensity value.\n","    #                       If set to 1, pad it with replications of the pixels\n","    #                       on the boundary\n","    #       breast_mask: The binary breast mask\n","    #OUTPUT enhanced_image: The output image from MMS\n","    #       \n","\n","\n","    newimage = image\n","    [m, n] = size(newimage)\n","\n","    #% Border effect control: border padding\n","    # Option 1: pad with highest pixel value\n","    temp = uint16(65535 * ones(m + 4 * M1, n + 4 * M1))\n","    temp(mslice[2 * M1 + 1:2 * M1 + m], mslice[2 * M1 + 1:2 * M1 + n]).lvalue = newimage# Add white margins to each side of the image to prevent edge effect of morphological process\n","\n","    # Option 2: replicate the pixels on the border\n","    if padding_option == 1:\n","        if L_or_R == 1:        # left breast\n","            edge = newimage(mslice[:], mslice[1:min(n, 2 * M1)])\n","            temp(mslice[2 * M1 + 1:2 * M1 + m], mslice[2 * M1 - size(edge, 2) + 1:2 * M1]).lvalue = fliplr(edge)\n","        else:        # right breast\n","            edge = newimage(mslice[:], mslice[max(1, n - 2 * M1 + 1):n])\n","            temp(mslice[2 * M1 + 1:2 * M1 + m], mslice[n + 2 * M1 + 1:n + 2 * M1 + size(edge, 2)]).lvalue = fliplr(edge)\n","        end\n","    end\n","    #% Apply multi-scale morphological sifting\n","\n","    enhanced_image = zeros(size(temp))\n","    for k in mslice[1:length(orientation)]:\n","        B1 = strel(mstring('line'), M1, orientation(k))\n","        B2 = strel(mstring('line'), M2, orientation(k))\n","        bg1 = imopen(temp, B1)\n","        r1 = imsubtract(temp, bg1)\n","        r2 = imopen(r1, B2)\n","        enhanced_image = enhanced_image + double(r2)\n","\n","    end\n","\n","    enhanced_image = enhanced_image(mslice[2 * M1 + 1:2 * M1 + m], mslice[2 * M1 + 1:2 * M1 + n])# Reset the image into the original size\n","    [enhanced_image] = Normalization_mask(enhanced_image, breast_mask, 8)\n","\n","#end"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wRuDpRyK0UPu"},"source":["#@mfunction(\"new_im\")\n","def Normalization_mask(image=None, mask=None, mode=None):\n","    #UNTITLED5 Summary of this function goes here\n","    #   Detailed explanation goes here\n","    image = double(image)\n","    inten = image(mask == 1)\n","    mini = min(inten)\n","    maxi = max(inten)\n","\n","    image = (image - mini) /eldiv/ abs(maxi - mini)\n","    image(mask < 1).lvalue = 0\n","    if mode == 8:\n","        new_im = uint8(image * 255)\n","\n","    elif mode == 16:\n","        new_im = uint16(image * 65535)\n","\n","    elif strcmp(mode, string('double')):\n","        new_im = double(image)\n","    end\n","#end"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"id":"PAYuUrnY0US3","executionInfo":{"status":"error","timestamp":1615660215870,"user_tz":-360,"elapsed":813,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"e8b72c4e-87ca-4cb3-95c4-8bb284034d19"},"source":["# Try to feed in gradient and morphological filtered images in to different\n","# channal\n","\n","\n","image_path = 'scans\\\\preprocessed_image\\\\'\n","image_save_path = 'scans\\\\pseudo_color_image\\\\'\n","\n","\n","item_names = Read_files_in_folder(image_path, ('files'))\n","\n","mass_size_range_mm = mcat([15, 3689])# square mm\n","resolution = 0.07# spatial resolution of the INbreast mammograms, 0.07mm\n","resize_ratio = 1 / 4\n","mass_diameter_range_pixel = mcat([floor((mass_size_range_mm(1) / pi) ** 0.5 * 2 / (resolution / resize_ratio)), ceil((mass_size_range_mm(2) / pi) ** 0.5 * 2 / (resolution / resize_ratio))])# diameter range in pixels\n","\n","for i in mslice[1:length(item_names)]:\n","    close(mstring('all'))\n","    disp(item_names(i))\n","    image = imread(strcat(image_path, item_names(i)))\n","\n","    #% Image subsampling using 2 level db2 wavelet\n","    image = image(mslice[:], mslice[:], 1)\n","    breast_mask = (image > 0)\n","    dwt2(image, mstring('db2'))\n","    dwt2(cA, mstring('db2'))\n","\n","    dwt2(breast_mask, mstring('db2'))\n","    dwt2(cA, mstring('db2'))\n","    breast_mask = (breast_mask >= 1)\n","\n","\n","    # Normalize the grayscale image\n","    [new_im] = Normalization_mask(image, breast_mask, 8)\n","    #     figure,imshow(new_im);\n","\n","    #% Apply multi-scale morphological sifting and append the images from 2 scales to the grayscale mammogram\n","    L_OR_R = isempty(strfind(item_names(i), mstring('_R_')))# check if it is a left or right breast\n","    CC_OR_ML = isempty(strfind(item_names(i), mstring('_CC_')))\n","    degree_bank = mslice[0:10:170]# The orientations of the linear structuring elements (LSEs)\n","    Num_scale = 2# Using 2 scales\n","    # Generate the length for LSEs on different scales\n","    [len_bank] = Morphological_filter_bank(Num_scale, mass_diameter_range_pixel, mstring('exponential'))\n","    enhanced_image = mcellarray([])\n","    for j in mslice[1:Num_scale]:\n","        # Boundary padding\n","        padding_mode = 1    #\n","        if j == 1 or CC_OR_ML == 1:\n","            #           if it is a small scale or it is a MLO view\n","            padding_mode = 0        # highest value padding\n","        end\n","        enhanced_image[j] = Morphological_sifter(len_bank(j + 1), len_bank(j), degree_bank, new_im, L_OR_R, padding_mode, breast_mask)\n","        #\n","    end\n","    Pseudo_color_im = cat(3, new_im, enhanced_image(1), enhanced_image(2))\n","    figure\n","    imshow(Pseudo_color_im)\n","\n","    imwrite(Pseudo_color_im, strcat(image_save_path, item_names(i)))\n","end\n","elapsedTime = toc\n","\n","#% Process the annotation masks, so that they are the same size as the mammograms\n","anno_path = mstring('scans\\\\preprocessed_mask\\\\')\n","anno_save_path = mstring('scans\\\\preprocessed_mask1\\\\')\n","if not exist(anno_save_path, mstring('dir')):\n","    mkdir(anno_save_path)\n","end\n","\n","item_names = Read_files_in_folder(anno_path, mstring('files'))\n","for i in mslice[1:length(item_names)]:\n","    anno = imread(strcat(anno_path, item_names(i)))\n","    anno(anno == 255).lvalue = 1\n","    anno = double(anno)\n","    dwt2(anno, mstring('db2'))\n","    dwt2(cA, mstring('db2'))\n","    anno = abs(anno)\n","    anno(anno >= 1).lvalue = 255\n","    anno(anno < 1).lvalue = 0\n","    anno = uint8(anno)\n","    imwrite(anno, strcat(anno_save_path, item_names(i)))\n","end\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-997fa4da8000>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mitem_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRead_files_in_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmass_size_range_mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3689\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# square mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-38-a62acc57cde3>\u001b[0m in \u001b[0;36mRead_files_in_folder\u001b[0;34m(path, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'short'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'mstring' is not defined"]}]},{"cell_type":"code","metadata":{"id":"YhjOhoBFUmb8"},"source":["!apt install octave"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IYHlUZMdWWpu"},"source":["!octave -W '/content/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN/Read_files_in_folder.m'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DiUOHBntWXqT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616006085318,"user_tz":-360,"elapsed":1417,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"2770d50a-a561-4fb3-ce1d-c1a4ed4ff097"},"source":["!octave -W '/content/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN/Morphological_filter_bank.m'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["error: Invalid call to type.  Correct usage is:\n","\n"," -- type NAME ...\n"," -- type -q NAME ...\n"," -- text = type (\"NAME\", ...)\n","error: called from\n","    print_usage at line 91 column 5\n","    type at line 38 column 5\n","    Morphological_filter_bank at line 12 column 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q5hQHjNqWXta"},"source":["!octave -W '/content/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN/Morphological_sifter.m'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KRHPDxAHW1Nc"},"source":["!octave -W '/content/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN/Normalization_mask.m'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pn-wN4Yde4Kn"},"source":["!octave -W '/content/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN/Pseudo_color_image_generation.m'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjLNwSwg7jsr"},"source":["!octave -W '/content/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN/Pseudo_color_image_generation.m'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T1b4SxuU7jv5","executionInfo":{"status":"ok","timestamp":1616009300753,"user_tz":-360,"elapsed":1638,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"7a7f6e09-72e5-4a7f-d22d-f01c6a359c4f"},"source":["!octave -W '/content/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN/Pseudo_color_image_generation.m'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","{\n","  [1,1] = 22580192_5530d5782fc89dd7_MG_R_CC_ANON.png\n","}\n","ami\n","22580192_5530d5782fc89dd7_MG_R_CC_ANON.png\n","error: 'dwt2' undefined near line 29 column 17\n","error: called from\n","    Pseudo_color_image_generation at line 29 column 15\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B3xt1o3HgJNp","executionInfo":{"status":"ok","timestamp":1616009305450,"user_tz":-360,"elapsed":3000,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"d0127d8a-75ba-4071-b2ae-e0c5fc2b528a"},"source":["pip install PyWavelets==0.2.2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting PyWavelets==0.2.2\n","  Using cached https://files.pythonhosted.org/packages/34/23/55501cba73984d1909a67170677b6a92b152448fca680ff062e40acd28f4/PyWavelets-0.2.2.zip\n","\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A1bL4GrpqVzY","executionInfo":{"status":"ok","timestamp":1616009412878,"user_tz":-360,"elapsed":848,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"242896df-20ff-4dc8-a1e3-c33df5e43c29"},"source":["!python untitled.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  File \"untitled.py\", line 1\n","    pip install PyWavelets\n","              ^\n","SyntaxError: invalid syntax\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SBoESKHvgSuc","executionInfo":{"status":"ok","timestamp":1616006697582,"user_tz":-360,"elapsed":4400,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"e9f23a93-2678-4f5a-c4f6-fa1c803620b7"},"source":["pip install PyWavelets"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (1.1.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from PyWavelets) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VTXwQLEz7jy7","colab":{"base_uri":"https://localhost:8080/","height":129},"executionInfo":{"status":"error","timestamp":1615831287334,"user_tz":-360,"elapsed":1236,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"8e4e69be-c1a8-4825-f8f8-b2e8edfcd6e0"},"source":["% Try to feed in gradient and morphological filtered images in to different\n","% channal\n","clc,clear,close all;\n","tic\n","\n","image_path = 'scans\\preprocessed_image\\';\n","image_save_path = 'scans\\pseudo_color_image\\';\n","\n","if ~exist(image_save_path,'dir')\n","    mkdir(image_save_path)\n","end\n","%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n","item_names = Read_files_in_folder( image_path, 'files' ); \n","\n","mass_size_range_mm = [15 3689];% square mm\n","resolution = 0.07;% spatial resolution of the INbreast mammograms, 0.07mm\n","resize_ratio = 1/4;\n","mass_diameter_range_pixel = [floor((mass_size_range_mm(1)/pi)^0.5*2/(resolution/resize_ratio)),...\n","    ceil((mass_size_range_mm(2)/pi)^0.5*2/(resolution/resize_ratio))];% diameter range in pixels\n","\n","for i = 1:length(item_names)\n","    close all;\n","    disp(item_names{i});\n","    image = imread(strcat(image_path,item_names{i}));\n","    \n","    %% Image subsampling using 2 level db2 wavelet\n","    image = image(:,:,1);\n","    breast_mask = (image>0);\n","    [cA,~,~,~] = dwt2(image,'db2');\n","    [image,~,~,~] = dwt2(cA,'db2');\n","    \n","    [cA,~,~,~] = dwt2(breast_mask,'db2');\n","    [breast_mask,~,~,~] = dwt2(cA,'db2');\n","    breast_mask = (breast_mask>=1);\n","    \n","    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n","    % Normalize the grayscale image\n","    [new_im] = Normalization_mask(image,breast_mask,8);\n","    %     figure,imshow(new_im);\n","    \n","    %% Apply multi-scale morphological sifting and append the images from 2 scales to the grayscale mammogram\n","    L_OR_R = isempty(strfind(item_names{i},'_R_'));% check if it is a left or right breast\n","    CC_OR_ML = isempty(strfind(item_names{i},'_CC_'));\n","    degree_bank = 0:10:170;% The orientations of the linear structuring elements (LSEs)\n","    Num_scale = 2; % Using 2 scales\n","    % Generate the length for LSEs on different scales\n","    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5\n","    [ len_bank ] = Morphological_filter_bank( Num_scale, mass_diameter_range_pixel, 'exponential' );\n","    enhanced_image = {};\n","    for j = 1:Num_scale\n","        % Boundary padding\n","        padding_mode = 1;%\n","        if j==1||CC_OR_ML==1\n","            %           if it is a small scale or it is a MLO view\n","            padding_mode = 0;% highest value padding\n","        end\n","        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n","        [enhanced_image{j}] = Morphological_sifter(len_bank(j+1),len_bank(j),degree_bank,new_im,L_OR_R, padding_mode, breast_mask);\n","        %\n","    end\n","    Pseudo_color_im = cat(3,new_im,enhanced_image{1},enhanced_image{2});\n","        figure,imshow(Pseudo_color_im);\n","        imwrite(Pseudo_color_im,strcat(image_save_path,item_names{i}));\n","end\n","elapsedTime = toc;\n","\n","%% Process the annotation masks, so that they are the same size as the mammograms\n","anno_path = 'scans\\preprocessed_mask\\';\n","anno_save_path = 'scans\\preprocessed_mask1\\';\n","if ~exist(anno_save_path,'dir')\n","    mkdir(anno_save_path)\n","end\n","\n","item_names = Read_files_in_folder( anno_path, 'files' );\n","for i = 1:length(item_names)\n","    anno = imread(strcat(anno_path,item_names{i}));\n","    anno(anno==255) = 1;\n","    anno= double(anno);\n","    [cA,~,~,~] = dwt2(anno,'db2');\n","    [anno,~,~,~] = dwt2(cA,'db2');\n","    anno = abs(anno);\n","    anno(anno>=1) = 255;\n","    anno(anno<1) = 0;\n","    anno = uint8(anno);\n","        imwrite(anno,strcat(anno_save_path,item_names{i}));\n","end"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-7d16d5d638d5>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    clc,clear,close all;\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"OUcP6Cz07j2D"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLudRvG_7j59"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0HERtwPdcnmo"},"source":["\n","pt=dir(image_path);\n","\n","item_names = {}; \n","\n","M=length(pt);\n","\n","k = 0;\n","\n","format short\n","\n","\n","for i = 1 : M\n","    if strcmp(pt (i).name, '.') || strcmp(pt (i).name, '..')||(pt(i).isdir==0 && strcmp('files','folder'))\n","        continue;\n","    else\n","            k = k + 1;\n","            item_names{k} = pt (i).name;\n","    end\n","    \n","end"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dFzs60mHtLtl"},"source":["image_path= '/content/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN/scans/Pseudo_color_image_generation.m'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YE99En0wtueF","executionInfo":{"status":"ok","timestamp":1615272098380,"user_tz":-360,"elapsed":1460,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"6b66f795-1020-45a1-deed-14b92fac8f72"},"source":["os.path.exists(image_path)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"4taAvt7htxcj"},"source":["% Root directory of the project\n","ROOT_DIR = os.getcwd()\n","\n","ROOT_DIR = ROOT_DIR+'/content/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN/scans/preprocessed_image/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5mOSL8nx2tW","executionInfo":{"status":"ok","timestamp":1615273327262,"user_tz":-360,"elapsed":1674,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"5f019c90-e4d7-46f8-a6f1-40330f4ed241"},"source":["print(ROOT_DIR)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/content/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN/scans/preprocessed_image/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4VjA6AEGx4zB"},"source":["% Try to feed in gradient and morphological filtered images in to different\n","% channal\n","clc,clear,close all;\n","tic\n","\n","\n","image_path = '/content/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN/scans/preprocessed_image/';\n","\n","image_save_path = '/content/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN/scans/pseudo_color_image/';\n","\n","if ~exist(image_save_path,'dir')\n","    mkdir(image_save_path)\n","end\n","\n","pt=dir(image_path);\n","\n","item_names = {}; \n","\n","M=length(pt);\n","\n","k = 0;\n","\n","format short\n","\n","\n","for i = 1 : M\n","    if strcmp(pt (i).name, '.') || strcmp(pt (i).name, '..')||(pt(i).isdir==0 && strcmp('files','folder'))\n","        continue;\n","    else\n","            k = k + 1;\n","            item_names{k} = pt (i).name;\n","    end\n","    \n","end\n","disp(item_names)\n","%item_names = Read_files_in_folder( image_path, 'files' );\n","\n","%caPathList = genpath('/content/Mammographic-mass-CAD-via-pseudo-color-mammogram-and-Mask-R-CNN/scans')\n","%disp(caPathList)\n","%Files=dir(image_path);\n","%for k=1:length(Files)\n","   %item_names=strcmp(Files(k).name, '..')\n","   %item_names= Files(k).isdir==0 && strcmp('files','folder')\n","%end\n","%(pt(i).isdir==0 && strcmp(mode,'folder'))\n","\n","\n","\n","\n","mass_size_range_mm = [15 3689];% square mm\n","resolution = 0.07;% spatial resolution of the INbreast mammograms, 0.07mm\n","resize_ratio = 1/4;\n","mass_diameter_range_pixel = [floor((mass_size_range_mm(1)/pi)^0.5*2/(resolution/resize_ratio)),...\n","    ceil((mass_size_range_mm(2)/pi)^0.5*2/(resolution/resize_ratio))];% diameter range in pixels\n","\n","for i = 1:length(item_names)\n","    close all;\n","    disp(item_names{i});\n","    image = imread(strcat(image_path,item_names{i}));\n","    %disp(length(image))\n","    \n","    %% Image subsampling using 2 level db2 wavelet\n","    image = image(:,:,1);\n","    breast_mask = (image>0);\n","    [cA,~,~,~] = dwt2(image,'db2');\n","    [image,~,~,~] = dwt2(cA,'db2');\n","    \n","    [cA,~,~,~] = dwt2(breast_mask,'db2');\n","    [breast_mask,~,~,~] = dwt2(cA,'db2');\n","    breast_mask = (breast_mask>=1);\n","    \n","    \n","    % Normalize the grayscale image\n","    [new_im] = Normalization_mask(image,breast_mask,8);\n","    %     figure,imshow(new_im);\n","    \n","    %% Apply multi-scale morphological sifting and append the images from 2 scales to the grayscale mammogram\n","    L_OR_R = isempty(strfind(item_names{i},'_R_'));% check if it is a left or right breast\n","    CC_OR_ML = isempty(strfind(item_names{i},'_CC_'));\n","    degree_bank = 0:10:170;% The orientations of the linear structuring elements (LSEs)\n","    Num_scale = 2; % Using 2 scales\n","    % Generate the length for LSEs on different scales\n","    [ len_bank ] = Morphological_filter_bank( Num_scale, mass_diameter_range_pixel, 'exponential' );\n","    enhanced_image = {};\n","    for j = 1:Num_scale\n","        % Boundary padding\n","        padding_mode = 1;%\n","        if j==1||CC_OR_ML==1\n","            %           if it is a small scale or it is a MLO view\n","            padding_mode = 0;% highest value padding\n","        end\n","        [enhanced_image{j}] = Morphological_sifter(len_bank(j+1),len_bank(j),degree_bank,new_im,L_OR_R, padding_mode, breast_mask);\n","        %\n","    end\n","    Pseudo_color_im = cat(3,new_im,enhanced_image{1},enhanced_image{2});\n","        figure,imshow(Pseudo_color_im);\n","        imwrite(Pseudo_color_im,strcat(image_save_path,item_names{i}));\n","end\n","elapsedTime = toc;\n","\n","%% Process the annotation masks, so that they are the same size as the mammograms\n","anno_path = 'scans\\preprocessed_mask\\';\n","anno_save_path = 'scans\\preprocessed_mask1\\';\n","if ~exist(anno_save_path,'dir')\n","    mkdir(anno_save_path)\n","end\n","\n","item_names = Read_files_in_folder( anno_path, 'files' );\n","for i = 1:length(item_names)\n","    anno = imread(strcat(anno_path,item_names{i}));\n","    anno(anno==255) = 1;\n","    anno= double(anno);\n","    [cA,~,~,~] = dwt2(anno,'db2');\n","    [anno,~,~,~] = dwt2(cA,'db2');\n","    anno = abs(anno);\n","    anno(anno>=1) = 255;\n","    anno(anno<1) = 0;\n","    anno = uint8(anno);\n","        imwrite(anno,strcat(anno_save_path,item_names{i}));\n","end"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jo4--nmjhEvy","colab":{"base_uri":"https://localhost:8080/","height":129},"executionInfo":{"status":"error","timestamp":1615285481139,"user_tz":-360,"elapsed":1608,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"10e3bde2-ec9f-46a0-b52b-d322eec12e54"},"source":["function [ item_names ] = Read_files_in_folder( path, mode )\n","% Read_files_in_folder Summary of this function goes here\n","%   Detailed explanation goes here\n","% This is a fuction that reads the files/folders under a folder path\n","%   INPUT   path   the folder path\n","%           mode   whether the user want read files or folders\n","%   OUTPUT  item_name    return the names of the items under the path\n","\n","pt=dir(path);\n","\n","item_names = {}; \n","\n","M=length(pt);\n","\n","k = 0;\n","\n","format short\n","\n","\n","for i = 1 : M\n","    if strcmp(pt (i).name, '.') || strcmp(pt (i).name, '..')||(pt(i).isdir==0 && strcmp('files','folder'))\n","        continue;\n","    else\n","            k = k + 1;\n","            item_names{k} = pt (i).name;\n","    end\n","    \n","end\n","\n","\n","    \n","\n","end\n","\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-94-a583e6109624>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    format short\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]}]}