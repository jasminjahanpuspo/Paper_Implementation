{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"part-part-check.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"le9nKV_EnWcN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620065806016,"user_tz":-360,"elapsed":5626,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7vBK7X5G_7pMqsoN85z2kfj6Dlrma_zrH9CrE=s64","userId":"06098240422498535684"}},"outputId":"a421eabc-ba92-4802-da30-5fca9f87271d"},"source":["!pip install keras==2.1.5"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting keras==2.1.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/65/e4aff762b8696ec0626a6654b1e73b396fcc8b7cc6b98d78a1bc53b85b48/Keras-2.1.5-py2.py3-none-any.whl (334kB)\n","\r\u001b[K     |█                               | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 10.6MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 6.5MB/s eta 0:00:01\r\u001b[K     |████                            | 40kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 102kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 112kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 122kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 133kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 143kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 153kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 163kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 174kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 184kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 194kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 204kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 215kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 225kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 235kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 245kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 256kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 266kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 276kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 286kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 296kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 307kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 317kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 327kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 337kB 5.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.19.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.4.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.15.0)\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.4.3\n","    Uninstalling Keras-2.4.3:\n","      Successfully uninstalled Keras-2.4.3\n","Successfully installed keras-2.1.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zt8WmS5jnh9Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620065851959,"user_tz":-360,"elapsed":51542,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7vBK7X5G_7pMqsoN85z2kfj6Dlrma_zrH9CrE=s64","userId":"06098240422498535684"}},"outputId":"f2bf7cf9-da34-40b4-dbdd-f916a1a717e8"},"source":["!pip install tensorflow==1.14.0\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n","\u001b[K     |████████████████████████████████| 109.3MB 86kB/s \n","\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n","\u001b[K     |████████████████████████████████| 491kB 45.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.19.5)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.12.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.12.4)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.3.3)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.36.2)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.12.1)\n","Collecting keras-applications>=1.0.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n","\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 41.0MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.32.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (56.0.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.4)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.10.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n","Installing collected packages: tensorflow-estimator, keras-applications, tensorboard, tensorflow\n","  Found existing installation: tensorflow-estimator 2.4.0\n","    Uninstalling tensorflow-estimator-2.4.0:\n","      Successfully uninstalled tensorflow-estimator-2.4.0\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","  Found existing installation: tensorflow 2.4.1\n","    Uninstalling tensorflow-2.4.1:\n","      Successfully uninstalled tensorflow-2.4.1\n","Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"stream","text":["1.14.0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eol5shtMnh_9","executionInfo":{"status":"ok","timestamp":1620066067599,"user_tz":-360,"elapsed":1122,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7vBK7X5G_7pMqsoN85z2kfj6Dlrma_zrH9CrE=s64","userId":"06098240422498535684"}},"outputId":"e6812d14-be29-43e6-be34-87c692d6778a"},"source":["cd '/content/drive/MyDrive/Mammographic'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1OhozUtMOASdwL2TG6wvn8dChDU-HPnEu/Mammographic\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MjQc0DDcddG4","executionInfo":{"status":"ok","timestamp":1620066055137,"user_tz":-360,"elapsed":22510,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7vBK7X5G_7pMqsoN85z2kfj6Dlrma_zrH9CrE=s64","userId":"06098240422498535684"}},"outputId":"956bf926-bb2d-44da-8419-b00910d0b46a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pY1iPfv6oHX6"},"source":["import os\n","import sys\n","import json\n","import datetime\n","import numpy as np\n","import skimage.draw\n","import matplotlib.image\n","import glob\n","import scipy.misc\n","from PIL import Image\n","#import imgaug \n","from imgaug import augmenters as iaa\n","import matplotlib.pyplot as plt\n","import imageio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mZbueykOoHav","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620066088719,"user_tz":-360,"elapsed":5653,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7vBK7X5G_7pMqsoN85z2kfj6Dlrma_zrH9CrE=s64","userId":"06098240422498535684"}},"outputId":"ba25a95e-464f-4b7a-f15f-859454b358e3"},"source":["# Root directory of the project\n","ROOT_DIR = os.getcwd()\n","ROOT_DIR = ROOT_DIR+\"/Mask_r_cnn\"\n","\n","MAMOGRAM_IMAGE_DIR = \"/scans/pseudo_color_image/\" #Path of the mammograms\n","MAMOGRAM_MASK_DIR = \"/scans/preprocessed_mask/\"# Path of the ground truth masks\n","\n","\n","# Import Mask RCNN\n","sys.path.append(ROOT_DIR) # To find local version of the library\n","from mrcnn.config import Config\n","from mrcnn import model as modellib, utils\n","\n","# Path to trained weights file\n","COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_balloon.h5\")\n","\n","# Directory to save logs and model checkpoints, if not provided\n","# through the command line argument --logs\n","DEFAULT_LOGS_DIR = os.path.join(\"/content/drive/MyDrive/Mammographic\", \"logs\")#Log directory for saving the weights\n","DEMO_SAVE_DIR = \"/scans/seg_mask/\"# path to save the segmentation masks"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9SdACgVvoVZR"},"source":["############################################################\n","#  Configurations\n","############################################################\n","\n","\n","class MamogramConfig(Config):\n","    \"\"\"Configuration for training on the toy  dataset.\n","    Derives from the base Config class and overrides some values.\n","    \"\"\"\n","    # Give the configuration a recognizable name\n","    NAME = \"mamogram\"\n","\n","    # We use a GPU with 12GB memory, which can fit two images.\n","    # Adjust down if you use a smaller GPU.\n","    IMAGES_PER_GPU = 1\n","\n","    # Number of classes (including background)\n","    NUM_CLASSES = 1 + 1  # Background + lesion\n","\n","    # Number of training steps per epoch,set to the number of training data here\n","    STEPS_PER_EPOCH = 5\n","\n","    # Number of validation steps after each round of training\n","    VALIDATION_STEPS = 2\n","    # Resize mode: \"none\" or \"square\"\n","\n","    IMAGE_RESIZE_MODE = \"square\"\n","    IMAGE_MIN_DIM = 1024\n","    IMAGE_MAX_DIM = 1024\n","\n","    # Skip detections with < DETECTION_MIN_CONFIDENCE\n","    DETECTION_MIN_CONFIDENCE = 0.965 # alter this during testing to generate different TPR at different FPI\n","    # 0.7 0.75 0.8 0.85 0.9"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ycKqZ1AGoaER"},"source":["############################################################\n","#  Dataset\n","############################################################\n","\n","class MamogramDataset(utils.Dataset):\n","\n","    def load_mamogram(self, subset):\n","        \"\"\"This method loads the actual image\n","        subset is either \"train\" or \"val\" depending on whether the image is part of the training or validation datasets \n","        \"\"\"\n","        # Add classes. We have only one class to add.\n","        # These are the things that will be segmented\n","        self.add_class(\"mamogram\", 1, \"lesion\")\n","\n","        # Train or validation dataset?\n","\n","        #list all the files in the directory with the mamogram images\n","        files = os.listdir(ROOT_DIR + MAMOGRAM_IMAGE_DIR + subset + \"/\")\n","        \n","        for fname in files:            \n","            self.add_image(\"mamogram\", image_id=fname, \n","                           path=ROOT_DIR + MAMOGRAM_IMAGE_DIR + subset +\"/\"+ fname, subset=subset, fname=fname)\n","\n","\n","    def load_mask(self, image_id):\n","        \"\"\"load the instance masks for an image.\n","        Returns:\n","        a tuple containing:\n","        masks: A bool array of shape [height, width, instance count] with\n","        one mask per instance.\n","        class_ids: a 1D array of class IDs of the instance masks.\n","        use dtype=np.int32\n","        \"\"\"\n","        image_info = self.image_info[image_id]\n","        info = self.image_info[image_id]\n","        fname = info['fname']\n","       \n","        files = glob.glob(ROOT_DIR + MAMOGRAM_MASK_DIR + info['subset']+\"/\" + fname[0:-4] + \"*\")\n","        \n","\n","        masks = []\n","        for i in range(0, len(files)):\n","            #print(i)\n","            data = skimage.io.imread(files[i])\n","            \n","            if data.ndim != 1:\n","                data = skimage.color.rgb2gray(data)\n","          \n","            singleMask = data\n","            if i == 0:\n","                masks = np.zeros((singleMask.shape[0], singleMask.shape[1], len(files)))\n","            masks[:,:,i] = singleMask\n","\n","        instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32))\n","        \n","        return (masks.astype(np.bool), instanceMaskMap)\n","\n","\n","        #class_ids = np.array([self.class_names.index(s[0]) for s in fname])\n","        #return mask.astype(np.bool), class_ids.astype(np.int32)\n","         #this is VERY important: array of class ids in the order that they appear in bigdata\n","        # Return mask, and array of class IDs of each instance. Since we have\n","        # one class ID only, we return an array of 1\n","\n","    def load_image(self, image_id):\n","        \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n","\t\tTaken from utils.py, any refinements we need can be done here\n","        \"\"\"\n","        # Load image\n","        image = skimage.io.imread(self.image_info[image_id]['path'])\n","        # If grayscale. Convert to RGB for consistency.\n","        if image.ndim != 3:\n","            image = skimage.color.gray2rgb(image)\n","        # If has an alpha channel, remove it for consistency\n","        if image.shape[-1] == 4:\n","            image = image[..., :3]\n","        return image\n","\n","    def image_reference(self, image_id):\n","        \"\"\"Return the path of the image.\"\"\"\n","        info = self.image_info[image_id]\n","        return info[\"path\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dsp3knpZoaG6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FTWMTngQoaMQ"},"source":["def train(model):\n","    \"\"\"Train the model.\"\"\"\n","    # Training dataset.\n","    dataset_train = MamogramDataset()\n","    dataset_train.load_mamogram(\"train\")\n","    dataset_train.prepare()\n","\n","    # Validation dataset\n","    dataset_val = MamogramDataset()\n","    dataset_val.load_mamogram(\"val\")\n","    dataset_val.prepare()\n","\n","\n","\n","\n","    # Image augmentation\n","    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n","    aug = iaa.Sequential([\n","        iaa.OneOf([iaa.Fliplr(0.5),\n","                   iaa.Flipud(0.5),\n","                   iaa.Affine(rotate=90),\n","                   iaa.Affine(rotate=180),\n","                   iaa.Affine(rotate=270)]),\n","    ])\n","\n","    # *** This training schedule is an example. Update to your needs ***\n","    # Since we're using a very small dataset, and starting from\n","    # COCO trained weights, we don't need to train too long. Also,\n","    # no need to train all layers, just the heads should do it.\n","    print(\"Training network heads\")\n","\n","    model.train(dataset_train, dataset_val,\n","                learning_rate=config.LEARNING_RATE,\n","                epochs=3,augmentation=aug,\n","                layers='heads')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"otDO6xRvoejg"},"source":["def segment(model, imPath):\n","    \n","    image = skimage.io.imread(imPath)\n","\n","    fname = imPath.split('/')[-1]\n","    mrcnnData = model.detect([image], verbose=1)\n","       # documentation for model.detect:\n","       # \"\"\"Runs the detection pipeline.\n","\n","       # images: List of images, potentially of different sizes.\n","\n","       # Returns a list of dicts, one dict per image. The dict contains:\n","       # rois: [N, (y1, x1, y2, x2)] detection bounding boxes\n","       # class_ids: [N] int class IDs\n","       # scores: [N] float probability scores for the class IDs\n","       # masks: [H, W, N] instance binary masks\n","       # \"\"\"\n","\n","    mrcnnData = mrcnnData[0] #model.detect takes a list of images, but here we only provide one image so the output is a list with just one element\n","\n","    masks = mrcnnData['masks']\n","    print(masks.shape[2])\n","    for i in range(0, masks.shape[2]):\n","        #iterate through the masks\n","        maskSingle = np.squeeze(masks[:, :, i])\n","        file_name =ROOT_DIR+ DEMO_SAVE_DIR + \"demo_mask_\" + str(i) + \"_\" + fname + \"_{:%Y%m%dT%H%M%S}.png\".format(datetime.datetime.now())\n","        \n","\n","        #scipy.misc.imsave(file_name, maskSingle.astype(np.int64))\n","        plt.imshow(maskSingle.astype(np.int8))\n","        #scipy.misc.imsave(file_name, maskSingle.astype(np.int64)) \n","        matplotlib.image.imsave(file_name, maskSingle.astype(np.int64))\n"," \n","\n","\n","    print(mrcnnData)\n","    print(\"&&&&&&&&&&&: \"+str(mrcnnData['rois']))\n","    print(\"&&&&&&&&&&&: \"+str(mrcnnData['class_ids']))\n","    print(\"&&&&&&&&&&&: \"+str(mrcnnData['scores']))\n","\n","    return\n","\n","def segmentWrapper(model, directory):\n","    \"\"\"wrapper function for segment to take many images as an input, calls segment() on everything in the directory\"\"\"\n","    files = os.listdir(directory)\n","    for f in files:\n","        segment(model, directory + '/' + f)\n","\n","def overlayResult(image, mask):\n","\t\"\"\"Function to overlay segmentation mask on an image.\n","\tusage: image_var = overlayResult(image, dict['masks'] || masks_var)\n","\t\n","\timage: RGB or grayscale image [height, width, 1 || 3].\n","\tmask: segmentation mask [height, width, instance_count]\n","\t\n","\treturns resulting image.\n","\t\"\"\"\n","\t# Image is already in grayscale so we skip converting it\n","\t# May need to create 3 dimensions if single dimension image though so\n","\t# will add this as a placeholder\n","\tgray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n","\t# Copy color pixels from the original color image where mask is set\n","\tif mask.shape[-1] > 0:\n","\t\t#collapse masks into one layer\n","\t\tmask = (np.sum(mask, -1, keepdims=True) >= 1)\n","\t\toverlay = np.where(mask, image, gray).astype(np.uint8)\n","\telse:\n","\t\toverlay = gray.astype(np.uint8)\n","\t\t\n","\treturn overlay"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2D6knBw4d2Xt","executionInfo":{"status":"ok","timestamp":1620066155713,"user_tz":-360,"elapsed":19864,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7vBK7X5G_7pMqsoN85z2kfj6Dlrma_zrH9CrE=s64","userId":"06098240422498535684"}},"outputId":"568bafe8-079e-481a-ac95-68f49366e7db"},"source":["##########Cross-------- Check  training \n","\n"," # Training dataset.\n","dataset_train = MamogramDataset()\n","dataset_train.load_mamogram(\"train\")\n","dataset_train.prepare()\n","\n","    # Validation dataset\n","dataset_val = MamogramDataset()\n","dataset_val.load_mamogram(\"val\")\n","dataset_val.prepare()\n","\n","config = MamogramConfig()\n","\n","model = modellib.MaskRCNN(mode=\"inference\", config=config,\n","                                  model_dir=DEFAULT_LOGS_DIR)\n","\n","\n","weights_path ='/content/drive/MyDrive/Mammographic/logs/mask_rcnn_mamogram_weights.h5'\n","\n","model.load_weights(weights_path, by_name=True)\n","\n","dataset = dataset_train\n","image_ids = np.random.choice(dataset.image_ids, 4)\n","for image_id in image_ids:\n","    image = dataset.load_image(image_id)\n","    masks, num_ids = dataset.load_mask(image_id)\n","    print(image,masks,num_ids)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3655: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1940: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/1OhozUtMOASdwL2TG6wvn8dChDU-HPnEu/Mammographic/Mask_r_cnn/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/1OhozUtMOASdwL2TG6wvn8dChDU-HPnEu/Mammographic/Mask_r_cnn/mrcnn/model.py:399: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/1OhozUtMOASdwL2TG6wvn8dChDU-HPnEu/Mammographic/Mask_r_cnn/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/1OhozUtMOASdwL2TG6wvn8dChDU-HPnEu/Mammographic/Mask_r_cnn/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n","\n","WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/1OhozUtMOASdwL2TG6wvn8dChDU-HPnEu/Mammographic/Mask_r_cnn/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n","\n","WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/1OhozUtMOASdwL2TG6wvn8dChDU-HPnEu/Mammographic/Mask_r_cnn/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","[[[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  0   0   0]\n","  [ 11   0   0]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  2   0   1]\n","  [ 17   0  12]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 55   0  34]\n","  [ 70   0  39]\n","  [ 83   0  50]]\n","\n"," ...\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [113   3  87]\n","  [117   2  89]\n","  [130   2  95]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 78   0  44]\n","  [ 85   0  50]\n","  [ 93   0  54]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 18   0   0]\n","  [ 21   0   0]\n","  [ 36   0   0]]] [[[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," ...\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]] [1]\n","[[[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  0   0   0]\n","  [ 11   0   0]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  2   0   1]\n","  [ 17   0  12]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 55   0  34]\n","  [ 70   0  39]\n","  [ 83   0  50]]\n","\n"," ...\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [113   3  87]\n","  [117   2  89]\n","  [130   2  95]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 78   0  44]\n","  [ 85   0  50]\n","  [ 93   0  54]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 18   0   0]\n","  [ 21   0   0]\n","  [ 36   0   0]]] [[[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," ...\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]] [1]\n","[[[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  0   0   0]\n","  [ 11   0   0]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  2   0   1]\n","  [ 17   0  12]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 55   0  34]\n","  [ 70   0  39]\n","  [ 83   0  50]]\n","\n"," ...\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [113   3  87]\n","  [117   2  89]\n","  [130   2  95]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 78   0  44]\n","  [ 85   0  50]\n","  [ 93   0  54]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 18   0   0]\n","  [ 21   0   0]\n","  [ 36   0   0]]] [[[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," ...\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]] [1]\n","[[[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  0   0   0]\n","  [ 11   0   0]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  2   0   1]\n","  [ 17   0  12]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 55   0  34]\n","  [ 70   0  39]\n","  [ 83   0  50]]\n","\n"," ...\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [113   3  87]\n","  [117   2  89]\n","  [130   2  95]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 78   0  44]\n","  [ 85   0  50]\n","  [ 93   0  54]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 18   0   0]\n","  [ 21   0   0]\n","  [ 36   0   0]]] [[[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," ...\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]] [1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3bN1DDSmomKZ","executionInfo":{"status":"ok","timestamp":1619716308626,"user_tz":-360,"elapsed":28355,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7vBK7X5G_7pMqsoN85z2kfj6Dlrma_zrH9CrE=s64","userId":"06098240422498535684"}},"outputId":"6c0b2d06-2b7b-4572-b7eb-5b9501e60b78"},"source":["##########Cross-------- Check  training \n","\n"," # Training dataset.\n","dataset_train = MamogramDataset()\n","dataset_train.load_mamogram(\"train\")\n","dataset_train.prepare()\n","\n","    # Validation dataset\n","dataset_val = MamogramDataset()\n","dataset_val.load_mamogram(\"val\")\n","dataset_val.prepare()\n","\n","config = MamogramConfig()\n","\n","model = modellib.MaskRCNN(mode=\"inference\", config=config,\n","                                  model_dir=DEFAULT_LOGS_DIR)\n","\n","\n","weights_path ='/content/drive/MyDrive/Mammographic/logs/mask_rcnn_mamogram_weights.h5'\n","\n","model.load_weights(weights_path, by_name=True)\n","\n","dataset = dataset_train\n","image_ids = np.random.choice(dataset.image_ids, 4)\n","for image_id in image_ids:\n","    image = dataset.load_image(image_id)\n","    masks, num_ids = dataset.load_mask(image_id)\n","    print(image,masks,num_ids)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3655: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1940: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/1OhozUtMOASdwL2TG6wvn8dChDU-HPnEu/Mammographic/Mask_r_cnn/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/1OhozUtMOASdwL2TG6wvn8dChDU-HPnEu/Mammographic/Mask_r_cnn/mrcnn/model.py:399: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/1OhozUtMOASdwL2TG6wvn8dChDU-HPnEu/Mammographic/Mask_r_cnn/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/1OhozUtMOASdwL2TG6wvn8dChDU-HPnEu/Mammographic/Mask_r_cnn/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n","\n","WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/1OhozUtMOASdwL2TG6wvn8dChDU-HPnEu/Mammographic/Mask_r_cnn/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n","\n","WARNING:tensorflow:From /content/drive/.shortcut-targets-by-id/1OhozUtMOASdwL2TG6wvn8dChDU-HPnEu/Mammographic/Mask_r_cnn/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","[[[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  0   0   0]\n","  [ 11   0   0]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  2   0   1]\n","  [ 17   0  12]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 55   0  34]\n","  [ 70   0  39]\n","  [ 83   0  50]]\n","\n"," ...\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [113   3  87]\n","  [117   2  89]\n","  [130   2  95]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 78   0  44]\n","  [ 85   0  50]\n","  [ 93   0  54]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 18   0   0]\n","  [ 21   0   0]\n","  [ 36   0   0]]] [[[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," ...\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]] [1]\n","[[[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  0   0   0]\n","  [ 11   0   0]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  2   0   1]\n","  [ 17   0  12]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 55   0  34]\n","  [ 70   0  39]\n","  [ 83   0  50]]\n","\n"," ...\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [113   3  87]\n","  [117   2  89]\n","  [130   2  95]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 78   0  44]\n","  [ 85   0  50]\n","  [ 93   0  54]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 18   0   0]\n","  [ 21   0   0]\n","  [ 36   0   0]]] [[[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," ...\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]] [1]\n","[[[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  0   0   0]\n","  [ 11   0   0]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  2   0   1]\n","  [ 17   0  12]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 55   0  34]\n","  [ 70   0  39]\n","  [ 83   0  50]]\n","\n"," ...\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [113   3  87]\n","  [117   2  89]\n","  [130   2  95]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 78   0  44]\n","  [ 85   0  50]\n","  [ 93   0  54]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 18   0   0]\n","  [ 21   0   0]\n","  [ 36   0   0]]] [[[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," ...\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]] [1]\n","[[[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  0   0   0]\n","  [ 11   0   0]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  2   0   1]\n","  [ 17   0  12]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 55   0  34]\n","  [ 70   0  39]\n","  [ 83   0  50]]\n","\n"," ...\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [113   3  87]\n","  [117   2  89]\n","  [130   2  95]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 78   0  44]\n","  [ 85   0  50]\n","  [ 93   0  54]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 18   0   0]\n","  [ 21   0   0]\n","  [ 36   0   0]]] [[[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," ...\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]] [1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"f-xe9DAx6iVo","executionInfo":{"status":"ok","timestamp":1618166393430,"user_tz":-360,"elapsed":22813,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"b619f8a3-c150-4c26-96d6-df9c871fae57"},"source":["config = MamogramConfig()\n","model = modellib.MaskRCNN(mode=\"inference\", config=config,\n","                                  model_dir=DEFAULT_LOGS_DIR)\n","weights_path ='/content/drive/MyDrive/Mammographic/logs/mask_rcnn_mamogram_weights.h5'\n","\n","model.load_weights(weights_path, by_name=True)\n","\n","segment(model, '/content/drive/MyDrive/Mammographic/Mask_r_cnn/scans/pseudo_color_image/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Processing 1 images\n","image                    shape: (681, 681, 3)         min:    0.00000  max:  255.00000  uint8\n","molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  150.10000  float64\n","image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n","anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n","{'rois': array([[267, 468, 324, 530]], dtype=int32), 'class_ids': array([1], dtype=int32), 'scores': array([0.9939551], dtype=float32), 'masks': array([[[False],\n","        [False],\n","        [False],\n","        ...,\n","        [False],\n","        [False],\n","        [False]],\n","\n","       [[False],\n","        [False],\n","        [False],\n","        ...,\n","        [False],\n","        [False],\n","        [False]],\n","\n","       [[False],\n","        [False],\n","        [False],\n","        ...,\n","        [False],\n","        [False],\n","        [False]],\n","\n","       ...,\n","\n","       [[False],\n","        [False],\n","        [False],\n","        ...,\n","        [False],\n","        [False],\n","        [False]],\n","\n","       [[False],\n","        [False],\n","        [False],\n","        ...,\n","        [False],\n","        [False],\n","        [False]],\n","\n","       [[False],\n","        [False],\n","        [False],\n","        ...,\n","        [False],\n","        [False],\n","        [False]]])}\n","&&&&&&&&&&&: [[267 468 324 530]]\n","&&&&&&&&&&&: [1]\n","&&&&&&&&&&&: [0.9939551]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARaUlEQVR4nO3df2yd1X3H8fcnthMDgfwCsizOliAClE0DUjeEgRhLCoK0ajKJMVhVLJTK00YnKti6sE6bWlUTTKMUWBuaEZjp+JWG0qQoLQ2Bauo2AoYECDEhhhLFHsEUEkNJk+bHd3/cY7gEU1/b91dzPi/p6p7nPOe53+Nr5+PnuffGRxGBmeVrTK0nYGa15RAwy5xDwCxzDgGzzDkEzDLnEDDLXEVCQNLFkrZK6pa0tBI1zKw8VO7PCUhqAF4CLgR6gKeAKyJiS1kLmVlZVOJMYC7QHRGvRMSvgPuBRRWoY2Zl0FiBx5wO7Cja7gHO/nUHjNW4aOaYCkzFzAa8w66fR8QJh/dXIgRKIqkdaAdo5mjO1oJaTcUsC4/Gqu2D9VficqAXmFG03ZL6PiAilkdEa0S0NjGuAtMws1JUIgSeAmZLmiVpLHA5sKYCdcysDMp+ORARByR9AXgEaADujIgXyl3HzMqjIq8JRMRaYG0lHtvMysufGDTLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzA0ZApLulNQnaXNR32RJ6yRtS/eTUr8k3SqpW9JzkuZUcvJmNnqlnAn8B3DxYX1LgfURMRtYn7YBLgFmp1s7sKw80zSzShkyBCLiv4C3DuteBHSkdgewuKj/7ih4ApgoaVq5Jmtm5TfS1wSmRsRrqb0TmJra04EdReN6Ut+HSGqX1Cmpcz/7RjgNMxutUb8wGBEBxAiO89LkZnVgpCHw+sBpfrrvS/29wIyicS2pz8zq1EhDYA3QltptwOqi/ivTuwTzgP6iywYzq0NDLk0u6T7gAuB4ST3APwE3ACslLQG2A5el4WuBhUA3sAe4qgJzNrMyGjIEIuKKj9i1YJCxAVw92kmZWfX4E4NmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFglrkhQ0DSDEmPS9oi6QVJ16T+yZLWSdqW7ielfkm6VVK3pOckzan0F2FmI1fKmcAB4LqIOB2YB1wt6XRgKbA+ImYD69M2wCXA7HRrB5aVfdZmVjZDhkBEvBYRz6T2O0AXheXGFwEdaVgHsDi1FwF3R8ETwMSBxUvNrP4M6zUBSTOBs4ANwNSixUZ3AlNTezqwo+iwntR3+GO1S+qU1LmffcOctpmVS8khIGk88CDwxYh4u3hfWoMwhlM4IpZHRGtEtDYxbjiHmlkZlRQCkpooBMA9EfG91P36wGl+uu9L/b3AjKLDW1KfmdWhUt4dELAC6IqIrxftWgO0pXYbsLqo/8r0LsE8oL/ossHM6syQS5MD5wKfA56XtCn1/T1wA7BS0hJgO3BZ2rcWWAh0A3uAq8o6YzMrqyFDICJ+Cugjdi8YZHwAV49yXmZWJf7EoFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGXOIWCWOYeAZU2NjTScejKH/ugsGiZNqvV0aqKUPy9mdkQa09zM1n89g3sXfouWxl+y9t1TuOGpi5nVIcY+8SKH3n231lOsCp8JWJbGNDez9aYz2Lz4NuY1N9DSOJ72Cf/HK5+8k467bkEPT+DA/I+jxiP/96RDwLLTcPIsdj80nc2LbuPoMWM/tL+lcTxrT13LHXfdwvb7PkbjtN+qwSyrxyFgeZF48R8m879nPDhoABSb1TSernO/w9abHAJmR4z+Pz+bH1zwb8M65p9bHzqizwYcApaNfZ/6BLd+7TZ+b+xRwzrulKY+GPfrzxp+k5WyAlGzpCclPSvpBUlfSf2zJG2Q1C3pAUljU/+4tN2d9s+s7JdgNrSG2Sfx8a8+zdxxTbWeSt0p5UxgHzA/Is4AzgQuTsuL3QjcHBEnA7uAJWn8EmBX6r85jTOrHYmu647npmnPjOjwlbs/Qby1u8yTqh9DhkAU/CJtNqVbAPOBVam/A1ic2ovSNmn/grSeoVlNqPX3+c+Lbh/RsQfjECsfPZeDb7899ODfUKWuStyQ1iHsA9YBLwO7I+JAGtIDTE/t6cAOgLS/H5gyyGO2S+qU1LmffaP7Ksw+QsPxUzhl2Yuc2zyyl79+sOc4Tvn2zjLPqr6U9MxExMGIOJPCMuNzgdNGWzgilkdEa0S0NjFutA9n9mESW788m5umPTGiww/GIf7m+5/jYPfPyjyx+jKseIyI3cDjwDnAREkDH6dqAXpTuxeYAZD2TwDeLMtszYahceqJfHXhd2lSw4iO//f+GUf8WQCU9u7ACZImpvZRwIVAF4UwuDQNawNWp/aatE3a/1haqdisqt6d8zv8yTGvjejY5f2/zYN/cdERfxYApf0HomlAh6QGCqGxMiIelrQFuF/S14CNwIo0fgXwHUndwFvA5RWYt9mQGvYeYk/s52hKf4//YBzinE1/xvF/K8Zs2VjB2dUP1cMv6eM0Oc7WglpPw44wY5qbefmuU/nhH36TY8eIo9XA+DHNHzm+/9Av+eSmNk64ahcH33ijijOtjkdj1dMR0Xp4/5H/X6QsW4f27uWkK7v4wsc+TzQ18IuZ43l97hgunL+R6058lDHAtv2T+FbvfLp+ehLT/ucAJ/z3Sxzc3V/rqVeVzwQsO2Oam9GsGSChPXs5sH0H1MG/g0rzmYBZcmjvXujaVutp1A3/ByKzzDkEzDLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8AscyWHQFqUdKOkh9P2LEkbJHVLekDS2NQ/Lm13p/0zKzN1MyuH4ZwJXENh+bEBNwI3R8TJwC5gSepfAuxK/TencWZWp0pdmrwF+BRwR9oWMB9YlYZ0AItTe1HaJu1fkMabWR0q9UzgG8CXgENpewqwOyIOpO0eYHpqTwd2AKT9/Wn8B0hql9QpqXM/+0Y4fTMbrVJWJf400BcRT5ezcEQsj4jWiGhtYlw5H9rMhqGUFYjOBT4jaSHQDBwH3AJMlNSYftu3AL1pfC8wA+iR1AhMAN4s+8zNrCyGPBOIiOsjoiUiZlJYZvyxiPgs8DhwaRrWBqxO7TVpm7T/saiHBQ/NbFCj+ZzA3wHXSuqmcM2/IvWvAKak/muBpaOboplV0rAWJI2InwA/Se1XgLmDjNkL/GkZ5mZmVeBPDJplziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5kpdlfhVSc9L2iSpM/VNlrRO0rZ0Pyn1S9KtkrolPSdpTiW/ADMbneGcCfxxRJwZEa1peymwPiJmA+t5f6WhS4DZ6dYOLCvXZM2s/EZzObAI6EjtDmBxUf/dUfAEhYVLp42ijplVUKkhEMCPJT0tqT31TY2I11J7JzA1tacDO4qO7Ul9HyCpXVKnpM797BvB1M2sHEpdi/C8iOiVdCKwTtKLxTsjIiQNa+XhiFgOLAc4TpO9arFZjZR0JhARvem+D3iIwkKkrw+c5qf7vjS8F5hRdHhL6jOzOjRkCEg6RtKxA23gImAzsAZoS8PagNWpvQa4Mr1LMA/oL7psMLM6U8rlwFTgIUkD4++NiB9JegpYKWkJsB24LI1fCywEuoE9wFVln7WZlc2QIRARrwBnDNL/JrBgkP4Ari7L7Mys4vyJQbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLXEkhIGmipFWSXpTUJekcSZMlrZO0Ld1PSmMl6VZJ3ZKekzSnsl+CmY1GqWcCtwA/iojTKCxE0gUsBdZHxGxgfdoGuASYnW7twLKyztjMyqqUtQgnAOcDKwAi4lcRsRtYBHSkYR3A4tReBNwdBU8AEwcWLjWz+lPKmcAs4A3gLkkbJd2RFiadWrTQ6E4KaxYCTAd2FB3fk/o+QFK7pE5JnfvZN/KvwMxGpZQQaATmAMsi4izgXd4/9QfeW38whlM4IpZHRGtEtDYxbjiHmlkZlRICPUBPRGxI26sohMLrA6f56b4v7e8FZhQd35L6zKwODRkCEbET2CHp1NS1ANgCrAHaUl8bsDq11wBXpncJ5gH9RZcNZlZnhlyaPPlr4B5JY4FXgKsoBMhKSUuA7cBlaexaYCHQDexJY82sTpUUAhGxCWgdZNeCQcYGcPUo52VmVeJPDJplziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZU+HvgtZ4EtI7wNYaTuF44Oeu7/pHeP3fjYgTDu8s9U+OV9rWiBjsrxlXhaRO13f9XOv7csAscw4Bs8zVSwgsd33Xd/3aqIsXBs2sdurlTMDMaqTmISDpYklbJXVLWlqhGndK6pO0uahvsqR1kral+0mpX5JuTfN5TtKcUdaeIelxSVskvSDpmirXb5b0pKRnU/2vpP5ZkjakOg+kxWaRNC5td6f9M0dTv2geDZI2Snq42vUlvSrpeUmbJHWmvqo8/+kxJ0paJelFSV2Szqlm/SFFRM1uQAPwMnASMBZ4Fji9AnXOB+YAm4v6/gVYmtpLgRtTeyHwQ0DAPGDDKGtPA+ak9rHAS8DpVawvYHxqNwEb0uOuBC5P/bcDf5nafwXcntqXAw+U6XtwLXAv8HDarlp94FXg+MP6qvL8p8fsAD6f2mOBidWsP+T8Kl1giCfnHOCRou3rgesrVGvmYSGwFZiW2tMofFYB4NvAFYONK9M8VgMX1qI+cDTwDHA2hQ+nNB7+fQAeAc5J7cY0TqOs2wKsB+YDD6cf8GrWHywEqvL8AxOAnx3+NdTq52+wW60vB6YDO4q2e1JfNUyNiNdSeycwtdJzSqe2Z1H4bVy1+ulUfBPQB6yjcPa1OyIODFLjvfppfz8wZTT1gW8AXwIOpe0pVa4fwI8lPS2pPfVV6/mfBbwB3JUuh+6QdEwV6w+p1iFQF6IQuRV9m0TSeOBB4IsR8XY160fEwYg4k8Jv5LnAaZWqdThJnwb6IuLpatUcxHkRMQe4BLha0vnFOyv8/DdSuBRdFhFnAe9SOP2vVv0h1ToEeoEZRdstqa8aXpc0DSDd91VqTpKaKATAPRHxvWrXHxARu4HHKZx+T5Q08LHx4hrv1U/7JwBvjqLsucBnJL0K3E/hkuCWKtYnInrTfR/wEIUgrNbz3wP0RMSGtL2KQihU/fv/UWodAk8Bs9MrxWMpvBC0pkq11wBtqd1G4Vp9oP/K9CrtPKC/6LRt2CQJWAF0RcTXa1D/BEkTU/soCq9HdFEIg0s/ov7AvC4FHku/qUYkIq6PiJaImEnh+/tYRHy2WvUlHSPp2IE2cBGwmSo9/xGxE9gh6dTUtQDYUq36pU6ypjcKr4a+ROE69csVqnEf8Bqwn0IyL6Fwnbke2AY8CkxOYwV8M83neaB1lLXPo3Cq9xywKd0WVrH+HwAbU/3NwD+m/pOAJ4Fu4LvAuNTfnLa70/6Tyvh9uID33x2oSv1U59l0e2HgZ6xaz396zDOBzvQ9+D4wqZr1h7r5E4Nmmav15YCZ1ZhDwCxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMvf/BS1rC8QytLIAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"l7BNfWIQomNh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618167252435,"user_tz":-360,"elapsed":844144,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"ae584fe7-cbd2-49d3-e318-e821729c876c"},"source":["config = MamogramConfig()\n","#config.display()\n","\n","model = modellib.MaskRCNN(mode=\"training\", config=config,\n","                                  model_dir=DEFAULT_LOGS_DIR)\n","\n","weights_path = COCO_WEIGHTS_PATH\n","\n","\n","model.load_weights(weights_path, by_name=True)\n","train(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training network heads\n","\n","Starting at epoch 0. LR=0.001\n","\n","Checkpoint Path: /content/drive/MyDrive/Mammographic/logs/mamogram20210411T1840/mask_rcnn_mamogram_{epoch:04d}.h5\n","Selecting layers to train\n","fpn_c5p5               (Conv2D)\n","fpn_c4p4               (Conv2D)\n","fpn_c3p3               (Conv2D)\n","fpn_c2p2               (Conv2D)\n","fpn_p5                 (Conv2D)\n","fpn_p2                 (Conv2D)\n","fpn_p3                 (Conv2D)\n","fpn_p4                 (Conv2D)\n","In model:  rpn_model\n","    rpn_conv_shared        (Conv2D)\n","    rpn_class_raw          (Conv2D)\n","    rpn_bbox_pred          (Conv2D)\n","mrcnn_mask_conv1       (TimeDistributed)\n","mrcnn_mask_bn1         (TimeDistributed)\n","mrcnn_mask_conv2       (TimeDistributed)\n","mrcnn_mask_bn2         (TimeDistributed)\n","mrcnn_class_conv1      (TimeDistributed)\n","mrcnn_class_bn1        (TimeDistributed)\n","mrcnn_mask_conv3       (TimeDistributed)\n","mrcnn_mask_bn3         (TimeDistributed)\n","mrcnn_class_conv2      (TimeDistributed)\n","mrcnn_class_bn2        (TimeDistributed)\n","mrcnn_mask_conv4       (TimeDistributed)\n","mrcnn_mask_bn4         (TimeDistributed)\n","mrcnn_bbox_fc          (TimeDistributed)\n","mrcnn_mask_deconv      (TimeDistributed)\n","mrcnn_class_logits     (TimeDistributed)\n","mrcnn_mask             (TimeDistributed)\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n","  UserWarning('Using a generator with `use_multiprocessing=True`'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:774: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:777: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","Epoch 1/3\n","4/5 [=======================>......] - ETA: 50s - loss: 156.5887 - rpn_class_loss: 23.1618 - rpn_bbox_loss: 133.4269 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 "],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2330: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n","  UserWarning('Using a generator with `use_multiprocessing=True`'\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 285s 57s/step - loss: 155.8546 - rpn_class_loss: 22.1052 - rpn_bbox_loss: 133.7494 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 289.6631 - val_rpn_class_loss: 15.7631 - val_rpn_bbox_loss: 273.9000 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n","Epoch 2/3\n","5/5 [==============================] - 222s 44s/step - loss: 205.2084 - rpn_class_loss: 8.7118 - rpn_bbox_loss: 196.4966 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 263.3696 - val_rpn_class_loss: 1.1882 - val_rpn_bbox_loss: 262.1815 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n","Epoch 3/3\n","5/5 [==============================] - 223s 45s/step - loss: 242.0677 - rpn_class_loss: 0.3595 - rpn_bbox_loss: 241.7082 - mrcnn_class_loss: 2.3842e-08 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 265.7005 - val_rpn_class_loss: 0.0538 - val_rpn_bbox_loss: 265.6467 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwAzYgocneFP","executionInfo":{"status":"ok","timestamp":1619717506245,"user_tz":-360,"elapsed":1169234,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7vBK7X5G_7pMqsoN85z2kfj6Dlrma_zrH9CrE=s64","userId":"06098240422498535684"}},"outputId":"b047754a-7e5b-4420-f40a-c4f75ee5f78a"},"source":["config = MamogramConfig()\n","#config.display()\n","\n","model = modellib.MaskRCNN(mode=\"training\", config=config,\n","                                  model_dir=DEFAULT_LOGS_DIR)\n","\n","weights_path = COCO_WEIGHTS_PATH\n","\n","\n","model.load_weights(weights_path, by_name=True)\n","train(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training network heads\n","\n","Starting at epoch 0. LR=0.001\n","\n","Checkpoint Path: /content/drive/MyDrive/Mammographic/logs/mamogram20210429T1712/mask_rcnn_mamogram_{epoch:04d}.h5\n","Selecting layers to train\n","fpn_c5p5               (Conv2D)\n","fpn_c4p4               (Conv2D)\n","fpn_c3p3               (Conv2D)\n","fpn_c2p2               (Conv2D)\n","fpn_p5                 (Conv2D)\n","fpn_p2                 (Conv2D)\n","fpn_p3                 (Conv2D)\n","fpn_p4                 (Conv2D)\n","In model:  rpn_model\n","    rpn_conv_shared        (Conv2D)\n","    rpn_class_raw          (Conv2D)\n","    rpn_bbox_pred          (Conv2D)\n","mrcnn_mask_conv1       (TimeDistributed)\n","mrcnn_mask_bn1         (TimeDistributed)\n","mrcnn_mask_conv2       (TimeDistributed)\n","mrcnn_mask_bn2         (TimeDistributed)\n","mrcnn_class_conv1      (TimeDistributed)\n","mrcnn_class_bn1        (TimeDistributed)\n","mrcnn_mask_conv3       (TimeDistributed)\n","mrcnn_mask_bn3         (TimeDistributed)\n","mrcnn_class_conv2      (TimeDistributed)\n","mrcnn_class_bn2        (TimeDistributed)\n","mrcnn_mask_conv4       (TimeDistributed)\n","mrcnn_mask_bn4         (TimeDistributed)\n","mrcnn_bbox_fc          (TimeDistributed)\n","mrcnn_mask_deconv      (TimeDistributed)\n","mrcnn_class_logits     (TimeDistributed)\n","mrcnn_mask             (TimeDistributed)\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n","  UserWarning('Using a generator with `use_multiprocessing=True`'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:774: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:777: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","Epoch 1/3\n","4/5 [=======================>......] - ETA: 1:09 - loss: 157.4555 - rpn_class_loss: 22.7847 - rpn_bbox_loss: 134.6707 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2330: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n","  UserWarning('Using a generator with `use_multiprocessing=True`'\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 406s 81s/step - loss: 157.5548 - rpn_class_loss: 21.6334 - rpn_bbox_loss: 135.9214 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 282.8493 - val_rpn_class_loss: 15.0273 - val_rpn_bbox_loss: 267.8220 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n","Epoch 2/3\n","5/5 [==============================] - 337s 67s/step - loss: 212.3183 - rpn_class_loss: 8.4674 - rpn_bbox_loss: 203.8509 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 271.0268 - val_rpn_class_loss: 1.1411 - val_rpn_bbox_loss: 269.8857 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n","Epoch 3/3\n","5/5 [==============================] - 329s 66s/step - loss: 245.1459 - rpn_class_loss: 0.3709 - rpn_bbox_loss: 244.7750 - mrcnn_class_loss: 2.3842e-08 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 272.3309 - val_rpn_class_loss: 0.0384 - val_rpn_bbox_loss: 272.2924 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9okUULG6xFq2"},"source":["from os import listdir\n","from xml.etree import ElementTree\n","from numpy import zeros\n","from numpy import asarray\n","from numpy import expand_dims\n","from numpy import mean\n","from mrcnn.config import Config\n","from mrcnn.model import MaskRCNN\n","from mrcnn.utils import Dataset\n","from mrcnn.utils import compute_ap\n","from mrcnn.model import load_image_gt\n","from mrcnn.model import mold_image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qAuRybtUxFvn"},"source":["def evaluate_model(dataset, model, cfg):\n","\tAPs = list()\n","\tfor image_id in dataset.image_ids:\n","\t\t# load image, bounding boxes and masks for the image id\n","\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n","\t\t# convert pixel values (e.g. center)\n","\t\tscaled_image = mold_image(image, cfg)\n","\t\t# convert image into one sample\n","\t\tsample = expand_dims(scaled_image, 0)\n","\t\t# make prediction\n","\t\tyhat = model.detect(sample, verbose=0)\n","\t\t# extract results for first sample\n","\t\tr = yhat[0]\n","\t\t# calculate statistics, including AP\n","\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n","\t\t# store\n","\t\tAPs.append(AP)\n","\t# calculate the mean AP across all images\n","\tmAP = mean(APs)\n","\treturn mAP"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pHVP_CrIyBVM"},"source":[" # Training dataset.\n","dataset_train = MamogramDataset()\n","dataset_train.load_mamogram(\"train\")\n","dataset_train.prepare()\n","\n","config = MamogramConfig()\n","\n","model = modellib.MaskRCNN(mode=\"inference\", config=config,\n","                                  model_dir=DEFAULT_LOGS_DIR)\n","\n","\n","weights_path ='/content/drive/MyDrive/Mammographic/logs/mask_rcnn_mamogram_weights.h5'\n","\n","model.load_weights(weights_path, by_name=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"YE7PfoX3xFzr","executionInfo":{"status":"error","timestamp":1619719156673,"user_tz":-360,"elapsed":18791,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7vBK7X5G_7pMqsoN85z2kfj6Dlrma_zrH9CrE=s64","userId":"06098240422498535684"}},"outputId":"1e18ab2b-a26a-42ab-aaa0-7fce7f3e48f6"},"source":["train_mAP = evaluate_model(dataset_train, model, config)\n","print(\"Train mAP: %.3f\" % train_mAP)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-bf53d3da1e9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_mAP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train mAP: %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtrain_mAP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-07c4b3ea6b07>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(dataset, model, cfg)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;31m# calculate statistics, including AP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mAP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_ap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_bbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_class_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rois\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scores\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'masks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;31m# store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mAPs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1OhozUtMOASdwL2TG6wvn8dChDU-HPnEu/Mammographic/Mask_r_cnn/mrcnn/utils.py\u001b[0m in \u001b[0;36mcompute_ap\u001b[0;34m(gt_boxes, gt_class_ids, gt_masks, pred_boxes, pred_class_ids, pred_scores, pred_masks, iou_threshold)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0mgt_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_class_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_masks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0mpred_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_class_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_masks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         iou_threshold)\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;31m# Compute precision and recall at each prediction box step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1OhozUtMOASdwL2TG6wvn8dChDU-HPnEu/Mammographic/Mask_r_cnn/mrcnn/utils.py\u001b[0m in \u001b[0;36mcompute_matches\u001b[0;34m(gt_boxes, gt_class_ids, gt_masks, pred_boxes, pred_class_ids, pred_scores, pred_masks, iou_threshold, score_threshold)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[0;31m# Compute IoU overlaps [pred_masks, gt_masks]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m     \u001b[0moverlaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_overlaps_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[0;31m# Loop through predictions and find matching ground truth boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1OhozUtMOASdwL2TG6wvn8dChDU-HPnEu/Mammographic/Mask_r_cnn/mrcnn/utils.py\u001b[0m in \u001b[0;36mcompute_overlaps_masks\u001b[0;34m(masks1, masks2)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# intersections and union\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mintersections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0munion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marea1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0marea2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mintersections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0moverlaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintersections\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0munion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: shapes (1,1048576) and (16703569,1) not aligned: 1048576 (dim 1) != 16703569 (dim 0)"]}]},{"cell_type":"code","metadata":{"id":"rT4b_Wp3xF7R"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S1_EeG0jph0x"},"source":["##  Now run testing  using command "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S6tP8VRxph34","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618167313099,"user_tz":-360,"elapsed":24477,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"f8f7c51b-acc8-4fe1-f11f-6f92629b248e"},"source":["!python mammo.py segment --weights=logs/mask_rcnn_mamogram_weights.h5 --image='/content/drive/MyDrive/Mammographic/Mask_r_cnn/scans/pseudo_color_image/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","Using TensorFlow backend.\n","\n","Configurations:\n","BACKBONE                       resnet101\n","BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n","BATCH_SIZE                     1\n","BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n","COMPUTE_BACKBONE_SHAPE         None\n","DETECTION_MAX_INSTANCES        100\n","DETECTION_MIN_CONFIDENCE       0.965\n","DETECTION_NMS_THRESHOLD        0.3\n","FPN_CLASSIF_FC_LAYERS_SIZE     1024\n","GPU_COUNT                      1\n","GRADIENT_CLIP_NORM             5.0\n","IMAGES_PER_GPU                 1\n","IMAGE_CHANNEL_COUNT            3\n","IMAGE_MAX_DIM                  1024\n","IMAGE_META_SIZE                14\n","IMAGE_MIN_DIM                  1024\n","IMAGE_MIN_SCALE                0\n","IMAGE_RESIZE_MODE              square\n","IMAGE_SHAPE                    [1024 1024    3]\n","LEARNING_MOMENTUM              0.9\n","LEARNING_RATE                  0.001\n","LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n","MASK_POOL_SIZE                 14\n","MASK_SHAPE                     [28, 28]\n","MAX_GT_INSTANCES               100\n","MEAN_PIXEL                     [123.7 116.8 103.9]\n","MINI_MASK_SHAPE                (56, 56)\n","NAME                           mamogram\n","NUM_CLASSES                    2\n","POOL_SIZE                      7\n","POST_NMS_ROIS_INFERENCE        1000\n","POST_NMS_ROIS_TRAINING         2000\n","PRE_NMS_LIMIT                  6000\n","ROI_POSITIVE_RATIO             0.33\n","RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n","RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n","RPN_ANCHOR_STRIDE              1\n","RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n","RPN_NMS_THRESHOLD              0.7\n","RPN_TRAIN_ANCHORS_PER_IMAGE    256\n","STEPS_PER_EPOCH                5\n","TOP_DOWN_PYRAMID_SIZE          256\n","TRAIN_BN                       False\n","TRAIN_ROIS_PER_IMAGE           200\n","USE_MINI_MASK                  True\n","USE_RPN_ROIS                   True\n","VALIDATION_STEPS               2\n","WEIGHT_DECAY                   0.0001\n","\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3655: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1940: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Mammographic/Mask_r_cnn/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Mammographic/Mask_r_cnn/mrcnn/model.py:399: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/My Drive/Mammographic/Mask_r_cnn/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /content/drive/My Drive/Mammographic/Mask_r_cnn/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Mammographic/Mask_r_cnn/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Mammographic/Mask_r_cnn/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","Loading weights  logs/mask_rcnn_mamogram_weights.h5\n","2021-04-11 18:54:59.830583: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2021-04-11 18:54:59.834529: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1999995000 Hz\n","2021-04-11 18:54:59.834777: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a5adb48300 executing computations on platform Host. Devices:\n","2021-04-11 18:54:59.834815: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n","2021-04-11 18:55:01.694580: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n","Processing 1 images\n","image                    shape: (681, 681, 3)         min:    0.00000  max:  255.00000  uint8\n","molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  150.10000  float64\n","image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n","anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n","{'rois': array([[267, 468, 324, 530]], dtype=int32), 'class_ids': array([1], dtype=int32), 'scores': array([0.9939551], dtype=float32), 'masks': array([[[False],\n","        [False],\n","        [False],\n","        ...,\n","        [False],\n","        [False],\n","        [False]],\n","\n","       [[False],\n","        [False],\n","        [False],\n","        ...,\n","        [False],\n","        [False],\n","        [False]],\n","\n","       [[False],\n","        [False],\n","        [False],\n","        ...,\n","        [False],\n","        [False],\n","        [False]],\n","\n","       ...,\n","\n","       [[False],\n","        [False],\n","        [False],\n","        ...,\n","        [False],\n","        [False],\n","        [False]],\n","\n","       [[False],\n","        [False],\n","        [False],\n","        ...,\n","        [False],\n","        [False],\n","        [False]],\n","\n","       [[False],\n","        [False],\n","        [False],\n","        ...,\n","        [False],\n","        [False],\n","        [False]]])}\n","&&&&&&&&&&&: [[267 468 324 530]]\n","&&&&&&&&&&&: [1]\n","&&&&&&&&&&&: [0.9939551]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qWoeFPyeGXA4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"58bDp4IlGXjb"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3VWIln1cGXmV","executionInfo":{"status":"ok","timestamp":1619640569545,"user_tz":-360,"elapsed":19381,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"9044c1a0-ea19-4a6e-e2fb-49d358350091"},"source":["##########Cross-------- Check  training \n","\n"," # Training dataset.\n","dataset_train = MamogramDataset()\n","dataset_train.load_mamogram(\"train\")\n","dataset_train.prepare()\n","\n","    # Validation dataset\n","dataset_val = MamogramDataset()\n","dataset_val.load_mamogram(\"val\")\n","dataset_val.prepare()\n","\n","config = MamogramConfig()\n","\n","model = modellib.MaskRCNN(mode=\"inference\", config=config,\n","                                  model_dir=DEFAULT_LOGS_DIR)\n","\n","\n","weights_path ='/content/drive/MyDrive/Mammographic/logs/mask_rcnn_mamogram_weights.h5'\n","\n","model.load_weights(weights_path, by_name=True)\n","\n","dataset = dataset_train\n","image_ids = np.random.choice(dataset.image_ids, 4)\n","for image_id in image_ids:\n","    image = dataset.load_image(image_id)\n","    masks, num_ids = dataset.load_mask(image_id)\n","    print(image,masks,num_ids)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3655: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1940: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py:399: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","[[[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  0   0   0]\n","  [ 11   0   0]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  2   0   1]\n","  [ 17   0  12]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 55   0  34]\n","  [ 70   0  39]\n","  [ 83   0  50]]\n","\n"," ...\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [113   3  87]\n","  [117   2  89]\n","  [130   2  95]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 78   0  44]\n","  [ 85   0  50]\n","  [ 93   0  54]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 18   0   0]\n","  [ 21   0   0]\n","  [ 36   0   0]]] [[[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," ...\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]] [1]\n","[[[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  0   0   0]\n","  [ 11   0   0]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  2   0   1]\n","  [ 17   0  12]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 55   0  34]\n","  [ 70   0  39]\n","  [ 83   0  50]]\n","\n"," ...\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [113   3  87]\n","  [117   2  89]\n","  [130   2  95]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 78   0  44]\n","  [ 85   0  50]\n","  [ 93   0  54]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 18   0   0]\n","  [ 21   0   0]\n","  [ 36   0   0]]] [[[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," ...\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]] [1]\n","[[[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  0   0   0]\n","  [ 11   0   0]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  2   0   1]\n","  [ 17   0  12]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 55   0  34]\n","  [ 70   0  39]\n","  [ 83   0  50]]\n","\n"," ...\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [113   3  87]\n","  [117   2  89]\n","  [130   2  95]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 78   0  44]\n","  [ 85   0  50]\n","  [ 93   0  54]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 18   0   0]\n","  [ 21   0   0]\n","  [ 36   0   0]]] [[[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," ...\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]] [1]\n","[[[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  0   0   0]\n","  [ 11   0   0]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [  0   0   0]\n","  [  2   0   1]\n","  [ 17   0  12]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 55   0  34]\n","  [ 70   0  39]\n","  [ 83   0  50]]\n","\n"," ...\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [113   3  87]\n","  [117   2  89]\n","  [130   2  95]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 78   0  44]\n","  [ 85   0  50]\n","  [ 93   0  54]]\n","\n"," [[  0   0   0]\n","  [  0   0   0]\n","  [  0   0   0]\n","  ...\n","  [ 18   0   0]\n","  [ 21   0   0]\n","  [ 36   0   0]]] [[[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," ...\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]\n","\n"," [[False]\n","  [False]\n","  [False]\n","  ...\n","  [False]\n","  [False]\n","  [False]]] [1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uyiALk9HGiK1","executionInfo":{"status":"ok","timestamp":1619641740544,"user_tz":-360,"elapsed":1146598,"user":{"displayName":"Jasmin Jahan Puspo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrKQVqe7wC9jSaf9_-51xdh1f0mivy2S9SdHYt=s64","userId":"07570020587767099311"}},"outputId":"f231b074-5f88-4f9c-c0a8-3b116cbf3ef9"},"source":["config = MamogramConfig()\n","#config.display()\n","\n","model = modellib.MaskRCNN(mode=\"training\", config=config,\n","                                  model_dir=DEFAULT_LOGS_DIR)\n","\n","weights_path = COCO_WEIGHTS_PATH\n","\n","\n","model.load_weights(weights_path, by_name=True)\n","train(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training network heads\n","\n","Starting at epoch 0. LR=0.001\n","\n","Checkpoint Path: /content/drive/MyDrive/Mammographic/logs/mamogram20210428T2010/mask_rcnn_mamogram_{epoch:04d}.h5\n","Selecting layers to train\n","fpn_c5p5               (Conv2D)\n","fpn_c4p4               (Conv2D)\n","fpn_c3p3               (Conv2D)\n","fpn_c2p2               (Conv2D)\n","fpn_p5                 (Conv2D)\n","fpn_p2                 (Conv2D)\n","fpn_p3                 (Conv2D)\n","fpn_p4                 (Conv2D)\n","In model:  rpn_model\n","    rpn_conv_shared        (Conv2D)\n","    rpn_class_raw          (Conv2D)\n","    rpn_bbox_pred          (Conv2D)\n","mrcnn_mask_conv1       (TimeDistributed)\n","mrcnn_mask_bn1         (TimeDistributed)\n","mrcnn_mask_conv2       (TimeDistributed)\n","mrcnn_mask_bn2         (TimeDistributed)\n","mrcnn_class_conv1      (TimeDistributed)\n","mrcnn_class_bn1        (TimeDistributed)\n","mrcnn_mask_conv3       (TimeDistributed)\n","mrcnn_mask_bn3         (TimeDistributed)\n","mrcnn_class_conv2      (TimeDistributed)\n","mrcnn_class_bn2        (TimeDistributed)\n","mrcnn_mask_conv4       (TimeDistributed)\n","mrcnn_mask_bn4         (TimeDistributed)\n","mrcnn_bbox_fc          (TimeDistributed)\n","mrcnn_mask_deconv      (TimeDistributed)\n","mrcnn_class_logits     (TimeDistributed)\n","mrcnn_mask             (TimeDistributed)\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n","  UserWarning('Using a generator with `use_multiprocessing=True`'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:774: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:777: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","Epoch 1/3\n","4/5 [=======================>......] - ETA: 1:07 - loss: 159.9972 - rpn_class_loss: 23.1611 - rpn_bbox_loss: 136.8361 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2330: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n","  UserWarning('Using a generator with `use_multiprocessing=True`'\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 396s 79s/step - loss: 158.1844 - rpn_class_loss: 22.1317 - rpn_bbox_loss: 136.0527 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 277.9507 - val_rpn_class_loss: 14.8308 - val_rpn_bbox_loss: 263.1200 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n","Epoch 2/3\n","5/5 [==============================] - 324s 65s/step - loss: 210.5771 - rpn_class_loss: 8.6134 - rpn_bbox_loss: 201.9637 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 266.8801 - val_rpn_class_loss: 1.1524 - val_rpn_bbox_loss: 265.7276 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n","Epoch 3/3\n","5/5 [==============================] - 331s 66s/step - loss: 247.8148 - rpn_class_loss: 0.3833 - rpn_bbox_loss: 247.4315 - mrcnn_class_loss: 2.3842e-08 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 269.1696 - val_rpn_class_loss: 0.1050 - val_rpn_bbox_loss: 269.0645 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n"],"name":"stdout"}]}]}